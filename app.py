import streamlit as st
import pandas as pd
import re
from collections import Counter

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë„¤ì´ë²„ SEO NLU ë§ˆìŠ¤í„°", layout="wide")
st.title("ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ SEO í†µí•© ìµœì í™” (ì•ˆì •í™” ë²„ì „ 2.1)")
st.markdown("---")

class SEOManager:
    def __init__(self, df, user_exclude_list):
        self.df = df
        self.exclude_brands = set([
            'ë§¤ì¼', 'ì„œìš¸ìš°ìœ ', 'ì„œìš¸', 'ì—°ì„¸', 'ë‚¨ì–‘', 'ê±´êµ­', 'íŒŒìŠ¤í‡´ë¥´', 'ì¼ë™', 'í›„ë””ìŠ¤', 
            'ì†Œì™€ë‚˜ë¬´', 'ë¹™ê·¸ë ˆ', 'ì…€ë¡œëª¬', 'ë¹…ì›ë”', 'ë¯¸ê´‘ìŠ¤í† ì–´', 'ë°ì–´ë¦¬ë§ˆì¼“', 'ë„ë‚¨ìƒíšŒ', 
            'í¬ì°½ìœ ì—…', 'ë‹´í„°', 'ì—°ì„¸ìœ ì—…', 'ë§¤ì¼ìœ ì—…'
        ] + user_exclude_list)

    def normalize(self, text):
        if pd.isna(text): return ""
        text = re.sub(r'[\x00-\x1F\x7F]', '', str(text))
        return text.strip()

    def split_base_terms(self, text):
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', str(text))
        words = [w.strip() for w in text.split() if len(w.strip()) > 1]
        return [w for w in words if w not in self.exclude_brands and not any(c.isdigit() for c in w)]

    def reorder_for_readability(self, word_count_pairs):
        identity, form, usage, desc = ['ì „ì§€', 'ë¶„ìœ ', 'ìš°ìœ ', 'íƒˆì§€'], ['ë¶„ë§', 'ê°€ë£¨', 'ìŠ¤í‹±', 'ì•¡ìƒ'], ['ìíŒê¸°', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰', 'ì‹ìì¬', 'ì œê³¼', 'ì œë¹µ'], ['ì§„í•œ', 'ê³ ì†Œí•œ', 'ë§›ìˆëŠ”', 'ì¶”ì–µ']
        def get_priority(pair):
            word = pair[0]
            if any(c in word for c in identity): return 1
            if any(c in word for c in form): return 2
            if any(c in word for c in usage): return 3
            if any(c in word for c in desc): return 4
            return 5
        return sorted(word_count_pairs, key=lambda x: get_priority(x))

    def run_analysis(self, conv_input, add_input, total_count):
        # [1] ê³ ì • í‚¤ì›Œë“œ
        conv_keys = [self.normalize(w) for w in conv_input.split() if w.strip()]
        add_keys = [self.normalize(w) for w in add_input.split() if w.strip()]
        fixed_keywords = conv_keys + add_keys
        
        # [2] ìƒí’ˆëª… ë¶„ì„
        all_name_words = []
        for name in self.df['ìƒí’ˆëª…']:
            all_name_words.extend(self.split_base_terms(name))
        name_counts = Counter(all_name_words)
        auto_pairs = [(w, c) for w, c in name_counts.most_common(100) if w not in fixed_keywords]
        readable_auto = self.reorder_for_readability(auto_pairs[:max(0, total_count - len(fixed_keywords))])
        
        # [3] ìŠ¤í™ ë¶„ì„ (4ë²ˆì§¸ ë¦¬í„´ê°’ìš©)
        spec_list = []
        for spec in self.df['ìŠ¤í™'].dropna():
            parts = [p.strip() for p in str(spec).split('|')]
            spec_list.extend([p for p in parts if len(p) > 1 and p not in self.exclude_brands])
        spec_counts = Counter(spec_list).most_common(8)

        # [4] íƒœê·¸ ë¶„ì„ (í™•ì¥ì„± ê·¹ëŒ€í™”)
        tag_raw_list = []
        for row in self.df['ê²€ìƒ‰ì¸ì‹íƒœê·¸'].dropna():
            tags = [self.normalize(t) for t in str(row).split(',') if self.normalize(t)]
            tag_raw_list.extend([t for t in tags if not any(b in t for b in self.exclude_brands)])
        
        tag_freq_map = Counter(tag_raw_list)
        title_set = set(fixed_keywords + [p[0] for p in readable_auto])
        candidates = [(t, c) for t, c in tag_freq_map.most_common(300) if t not in title_set and not any(char.isdigit() for char in t)]

        final_tags = []
        used_prefixes = set()

        for t, c in candidates:
            if len(final_tags) >= 10: break
            prefix = t[:3] if len(t) > 3 else t[:2]
            
            is_redundant = False
            for ex_t, _ in final_tags:
                # ìˆ˜ì‹ì–´ ì¤‘ë³µ ë°°ì œ (ì¶”ì–µì˜ë§› vs ì¶”ì–µì˜ê°„ì‹)
                if prefix in ex_t or any(ex_t[:3] in t for ex_t, _ in final_tags if len(ex_t) > 2):
                    is_redundant = True; break
                # í¬í•¨ ê´€ê³„ ì²´í¬ (ê¸´ ë‹¨ì–´ ë³´ì¡´)
                if t in ex_t: is_redundant = True; break
            
            if not is_redundant:
                final_tags.append((t, c))
                used_prefixes.add(prefix)

        for t, c in candidates:
            if len(final_tags) >= 10: break
            if not any(t == ex[0] for ex in final_tags):
                final_tags.append((t, c))
        
        # â˜… ì´ 6ê°œì˜ ê°’ì„ ë¦¬í„´í•©ë‹ˆë‹¤ â˜…
        return conv_keys, add_keys, readable_auto, spec_counts, sorted(final_tags, key=lambda x: x[1], reverse=True)[:10], tag_freq_map.most_common(50)

def calculate_bytes(text):
    return len(text.encode('euc-kr', errors='replace'))

# 3. ì‚¬ì´ë“œë°” UI
st.sidebar.header("ğŸ“ Step 1. ë°ì´í„° ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("ë¶„ì„ìš© CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

st.sidebar.header("ğŸ¯ Step 2. ì „ëµ ì„¤ì •")
conversion_input = st.sidebar.text_input("êµ¬ë§¤ì „í™˜ í‚¤ì›Œë“œ")
add_input = st.sidebar.text_input("ì¶”ê°€í•  í‚¤ì›Œë“œ")
total_kw_count = st.sidebar.number_input("ìƒí’ˆëª… ì´ í‚¤ì›Œë“œ ìˆ˜", min_value=5, max_value=25, value=11)

if uploaded_file:
    try:
        df = pd.read_csv(uploaded_file, encoding='cp949')
    except UnicodeDecodeError:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')

    manager = SEOManager(df, [])
    # â˜… ë°›ëŠ” ìª½ì—ì„œë„ 6ê°œ ë³€ìˆ˜ë¥¼ ì •í™•íˆ ì§€ì •í–ˆìŠµë‹ˆë‹¤ â˜…
    conv, add, auto, specs, tags, raw_stats = manager.run_analysis(conversion_input, add_input, total_kw_count)

    st.success("âœ¨ ì˜¤ë¥˜ê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.")

    # 1. ìƒí’ˆëª… ì„¹ì…˜
    st.header("ğŸ·ï¸ 1. ì „ëµì  ìƒí’ˆëª… ì¡°í•©")
    full_title = " ".join(conv + add + [p[0] for p in auto])
    col1, col2 = st.columns([2, 1])
    with col1:
        st.code(full_title, language=None)
        m1, m2, m3 = st.columns(3)
        m1.metric("ì´ í‚¤ì›Œë“œ", f"{len(conv)+len(add)+len(auto)}ê°œ")
        m2.metric("ê¸€ì ìˆ˜", f"{len(full_title)}ì", delta="ğŸŸ¢ ì •ìƒ" if len(full_title) <= 50 else "ğŸ”´ ì´ˆê³¼", delta_color="normal" if len(full_title) <= 50 else "inverse")
        m3.metric("ë°”ì´íŠ¸", f"{calculate_bytes(full_title)}B")
    with col2:
        st.subheader("ğŸ“Š ìë™ í‚¤ì›Œë“œ ë¹ˆë„")
        st.table(pd.DataFrame(auto, columns=['ë‹¨ì–´', 'ë¹ˆë„']).assign(No=range(1, len(auto)+1)).set_index('No'))

    st.markdown("---")
    # 2. ì†ì„± ì„¹ì…˜ (specs í™œìš©)
    st.header("âš™ï¸ 2. í•„í„° ë…¸ì¶œìš© ì†ì„±ê°’")
    col3, col4 = st.columns([2, 1])
    with col3:
        for s, _ in specs: st.button(s, key=f"btn_{s}", use_container_width=True)
    with col4:
        st.table(pd.DataFrame(specs, columns=['ì†ì„±ê°’', 'ë¹ˆë„']).assign(No=range(1, len(specs)+1)).set_index('No'))

    st.markdown("---")
    # 3. íƒœê·¸ ì„¹ì…˜
    st.header("ğŸ” 3. í™•ì¥ ê²€ìƒ‰ íƒœê·¸ (ì¡°í•© í™•ì¥ì„± ê·¹ëŒ€í™”)")
    t_col1, t_col2 = st.columns([2, 1])
    with t_col1:
        st.warning(", ".join([f"#{t[0]}" for t in tags]))
        st.info("ğŸ’¡ **ìˆ˜ì‹ì–´ í•„í„°ë§:** '#ì¶”ì–µì˜ë§›'ì´ ìˆìœ¼ë©´ '#ì¶”ì–µì˜ê°„ì‹'ì€ ìë™ìœ¼ë¡œ ì œì™¸í•˜ì—¬ ìœ ì… ê²½ë¡œë¥¼ ë„“í˜”ìŠµë‹ˆë‹¤.")
    with t_col2:
        st.table(pd.DataFrame(raw_stats[:20], columns=['íƒœê·¸ëª…', 'ì‚¬ìš© ë¹ˆë„ìˆ˜']).assign(No=range(1, 21)).set_index('No'))
