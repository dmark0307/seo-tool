import streamlit as st
import pandas as pd
import re
from collections import Counter

# 1. í˜ì´ì§€ ì„¤ì • (ìµœìƒë‹¨ ê³ ì •)
st.set_page_config(page_title="ë„¤ì´ë²„ SEO NLU ë§ˆìŠ¤í„°", layout="wide")
st.title("ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ SEO í†µí•© ìµœì í™” ë§¤ë‹ˆì €")
st.markdown("---")

class SEOManager:
    def __init__(self, df, user_exclude_list):
        self.df = df
        self.exclude_brands = [
            'ë§¤ì¼', 'ì„œìš¸ìš°ìœ ', 'ì„œìš¸', 'ì—°ì„¸', 'ë‚¨ì–‘', 'ê±´êµ­', 'íŒŒìŠ¤í‡´ë¥´', 'ì¼ë™', 'í›„ë””ìŠ¤', 
            'ì†Œì™€ë‚˜ë¬´', 'ë¹™ê·¸ë ˆ', 'ì…€ë¡œëª¬', 'ë¹…ì›ë”', 'ë¯¸ê´‘ìŠ¤í† ì–´', 'ë°ì–´ë¦¬ë§ˆì¼“', 'ë„ë‚¨ìƒíšŒ', 
            'í¬ì°½ìœ ì—…', 'ë‹´í„°', 'ì—°ì„¸ìœ ì—…', 'ë§¤ì¼ìœ ì—…'
        ] + user_exclude_list
        self.sub_splits = sorted(['ìíŒê¸°', 'ìš°ìœ ', 'ë¶„ìœ ', 'ê°€ë£¨', 'ë¶„ë§', 'ì „ì§€', 'íƒˆì§€', 'ìŠ¤í‹±', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰', 'ë©¸ê· ', 'íŒŒìš°ì¹˜', 'ì¶”ì–µ', 'ê°„ì‹', 'ì¬ë£Œ'], key=len, reverse=True)

    def split_base_terms(self, text):
        if pd.isna(text) or text == '-': return []
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', str(text))
        raw_words = text.split()
        terms = []
        pattern = f"({'|'.join(self.sub_splits)})"
        for word in raw_words:
            if word in self.exclude_brands or any(char.isdigit() for char in word): continue
            parts = re.split(pattern, word)
            for p in parts:
                p = p.strip()
                if not p or p in self.exclude_brands: continue
                if len(p) > 1 or p in self.sub_splits: terms.append(p)
        return terms

    def extract_stats_keywords(self, stats_df, target_product_code):
        try:
            code_col = [c for c in stats_df.columns if any(x in c for x in ['ë²ˆí˜¸', 'ID', 'ì½”ë“œ'])][0]
            kw_col = [c for c in stats_df.columns if 'í‚¤ì›Œë“œ' in c][0]
            filtered_df = stats_df[stats_df[code_col].astype(str) == str(target_product_code)]
            raw_keywords = filtered_df[kw_col].dropna().unique().tolist()
            extracted = []
            for rk in raw_keywords:
                if rk != '-': extracted.extend(self.split_base_terms(rk))
            return list(dict.fromkeys(extracted))[:5]
        except: return []

    def run_analysis(self, stats_keywords, conversion_input, add_input, total_target_count):
        conv_keys = stats_keywords + self.split_base_terms(conversion_input)
        add_keys = self.split_base_terms(add_input)
        fixed_keywords = []
        for k in (conv_keys + add_keys):
            if k not in fixed_keywords: fixed_keywords.append(k)
        
        name_terms = []
        for name in self.df['ìƒí’ˆëª…']: name_terms.extend(self.split_base_terms(name))
        name_freq = Counter(name_terms).most_common(50)
        auto_candidates = [w for w, c in name_freq if w not in fixed_keywords]
        
        remain_count = max(0, total_target_count - len(fixed_keywords))
        selected_auto = auto_candidates[:remain_count]
        
        spec_list = []
        for spec in self.df['ìŠ¤í™'].dropna():
            parts = [p.strip() for p in str(spec).split('|')]
            spec_list.extend([p for p in parts if len(p) > 1 and p not in self.exclude_brands])
        spec_counts = Counter(spec_list).most_common(8)
        spec_keywords = set()
        for s, _ in spec_counts: spec_keywords.update(self.split_base_terms(s))

        title_keywords = set(fixed_keywords + selected_auto)
        tag_raw_list = []
        for tags in self.df['ê²€ìƒ‰ì¸ì‹íƒœê·¸'].dropna():
            tag_raw_list.extend([t.strip() for t in str(tags).split(',') if t.strip()])
        tag_freq = Counter(tag_raw_list).most_common(300)
        candidates = []
        for t_raw, c in tag_freq:
            if any(brand in t_raw for brand in self.exclude_brands): continue
            if any(char.isdigit() for char in t_raw): continue
            t_subterms = self.split_base_terms(t_raw)
            if not t_subterms or any(sub in title_keywords or sub in spec_keywords for sub in t_subterms): continue
            candidates.append((t_raw, c))

        final_tags, selected_subterms = [], set()
        for i, (t_raw, c) in enumerate(candidates):
            if len(final_tags) >= 10: break
            if any(t_raw in other_t and len(t_raw) < len(other_t) for other_t, _ in candidates): continue
            prefix = t_raw[:3] if len(t_raw) > 3 else t_raw[:2]
            if any(prefix in ex_t or ex_t[:3] in t_raw for ex_t, _ in final_tags): continue
            final_tags.append((t_raw, c)); selected_subterms.update(self.split_base_terms(t_raw))

        return fixed_keywords, [(w, Counter(name_terms)[w]) for w in selected_auto], spec_counts, sorted(final_tags, key=lambda x: x[1], reverse=True)[:10]

def calculate_seo_metrics(text):
    c_len = len(text)
    try: b_len = len(text.encode('euc-kr'))
    except: b_len = len(text.encode('utf-8'))
    return c_len, b_len

# --- ì¢Œì¸¡ ì‚¬ì´ë“œë°” ìµœì í™” êµ¬ì„± ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • ë° ë¶„ì„")
    
    # 1. ë°ì´í„° ì—…ë¡œë“œ ê·¸ë£¹ (ì ‘ê³  í¼ì¹˜ê¸° ê°€ëŠ¥)
    with st.expander("ğŸ“ ë°ì´í„° ì—…ë¡œë“œ", expanded=True):
        main_file = st.file_uploader("ìƒí’ˆ ë°ì´í„° (CSV)", type=["csv"])
        stats_file = st.file_uploader("íŒë§¤ë¶„ì„ í†µê³„ (Excel/CSV)", type=["csv", "xlsx"])
        target_code = st.text_input("ğŸ¯ ìµœì í™” ìƒí’ˆì½”ë“œ", placeholder="123456789")

    # 2. ì „ëµ í‚¤ì›Œë“œ ì„¤ì • ê·¸ë£¹
    with st.expander("ğŸ¯ ë¶„ì„ ì „ëµ ì„¤ì •", expanded=True):
        conv_in = st.text_input("êµ¬ë§¤ì „í™˜ í‚¤ì›Œë“œ ì¶”ê°€", help="í†µê³„ ì™¸ ì¶”ê°€í•  ë‹¨ì–´")
        add_in = st.text_input("ê³ ì • ë°°ì¹˜ í‚¤ì›Œë“œ", placeholder="ë¬´ë£Œë°°ì†¡ ë“±")
        total_kw = st.number_input("ëª©í‘œ í‚¤ì›Œë“œ ìˆ˜", value=11, min_value=5)

if main_file:
    try:
        main_file.seek(0)
        df = pd.read_csv(main_file, encoding='cp949')
    except:
        main_file.seek(0)
        df = pd.read_csv(main_file, encoding='utf-8-sig')

    manager = SEOManager(df, [])
    stats_kws = []
    
    if stats_file and target_code:
        try:
            stats_file.seek(0)
            if stats_file.name.endswith('.csv'):
                try: stats_df = pd.read_csv(stats_file, encoding='cp949')
                except: stats_df = pd.read_csv(stats_file, encoding='utf-8-sig')
            else:
                stats_df = pd.read_excel(stats_file, engine='openpyxl')
            stats_kws = manager.extract_stats_keywords(stats_df, target_code)
        except: st.sidebar.error("í†µê³„ ë¶„ì„ ì¤‘ (openpyxl í•„ìš”)")

    fixed, auto, specs, tags = manager.run_analysis(stats_kws, conv_in, add_in, total_kw)

    # 1. ìƒí’ˆëª… ì„¹ì…˜
    st.header("ğŸ·ï¸ 1. ì „ëµì  ìƒí’ˆëª… ì¡°í•©")
    full_title = " ".join(fixed + [p[0] for p in auto])
    st.code(full_title, language=None)
    c_l, b_l = calculate_seo_metrics(full_title)
    st.markdown(f"**{c_l}ì / {b_l} Byte / {len(fixed)+len(auto)}ê°œ í‚¤ì›Œë“œ**")
    
    st.markdown("---")
    
    # 2 & 3. ì†ì„± ë° íƒœê·¸ (ì´ë¯¸ì§€ 77c3cc ë ˆì´ì•„ì›ƒ ìœ ì§€)
    st.header("âš™ï¸ 2. í•„í„° ì†ì„± & ğŸ” 3. í™•ì¥ íƒœê·¸")
    l_col, r_col = st.columns(2)
    with l_col:
        for s_name, _ in specs: st.button(s_name, use_container_width=True, key=f"at_{s_name}")
    with r_col:
        st.success(", ".join([f"#{t[0]}" for t in tags]))
else:
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ìƒí’ˆ ë°ì´í„°ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
