import streamlit as st
import pandas as pd
import re
from collections import Counter

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë„¤ì´ë²„ SEO í†µí•© ë¶„ì„ ë„êµ¬", layout="wide")
st.title("ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ SEO í†µí•© ìµœì í™” ë§¤ë‹ˆì €")
st.markdown("---")

# 2. ì „ë¬¸ SEO ë¶„ì„ ë¡œì§ í´ë˜ìŠ¤
class SEOManager:
    def __init__(self, df):
        self.df = df
        # ì§€ì¬ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•œ í•„í„°ë§ ë¦¬ìŠ¤íŠ¸
        self.exclude_brands = [
            'ë§¤ì¼', 'ì„œìš¸ìš°ìœ ', 'ì„œìš¸', 'ì—°ì„¸', 'ë‚¨ì–‘', 'ê±´êµ­', 'íŒŒìŠ¤í‡´ë¥´', 'ì¼ë™', 'í›„ë””ìŠ¤', 
            'ì†Œì™€ë‚˜ë¬´', 'ë¹™ê·¸ë ˆ', 'ì…€ë¡œëª¬', 'ë¹…ì›ë”', 'ë¯¸ê´‘ìŠ¤í† ì–´', 'ë°ì–´ë¦¬ë§ˆì¼“', 'ë„ë‚¨ìƒíšŒ', 
            'í¬ì°½ìœ ì—…', 'ë‹´í„°', 'ì—°ì„¸ìœ ì—…', 'ë§¤ì¼ìœ ì—…'
        ]

    def split_base_terms(self, text):
        """ë³µí•© ëª…ì‚¬ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê¸°ì´ˆ ë‹¨ì–´(Base Term) ì¶”ì¶œ"""
        if pd.isna(text) or text == '-': return []
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', str(text))
        raw_words = text.split()
        
        terms = []
        sub_splits = ['ìíŒê¸°', 'ìš°ìœ ', 'ë¶„ìœ ', 'ê°€ë£¨', 'ë¶„ë§', 'ì „ì§€', 'íƒˆì§€', 'ìŠ¤í‹±', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰']
        
        for word in raw_words:
            if word in self.exclude_brands or word.isdigit(): continue
            found_sub = False
            for sub in sub_splits:
                if sub in word and word != sub:
                    terms.append(sub)
                    rem = word.replace(sub, '').strip()
                    if len(rem) > 1: terms.append(rem)
                    found_sub = True
                    break
            if not found_sub and len(word) > 1:
                terms.append(word)
        return terms

    def run_analysis(self):
        # [ìƒí’ˆëª… ë¶„ì„]
        name_terms = []
        for name in self.df['ìƒí’ˆëª…']:
            name_terms.extend(self.split_base_terms(name))
        name_counts = Counter(name_terms).most_common(20)
        top_12_names = [w for w, c in name_counts[:12]]

        # [ì†ì„± ë¶„ì„]
        spec_list = []
        for spec in self.df['ìŠ¤í™'].dropna():
            if spec != '-':
                parts = [p.strip() for p in str(spec).split('|')]
                spec_list.extend([p for p in parts if len(p) > 1 and p not in self.exclude_brands])
        spec_counts = Counter(spec_list).most_common(10)

        # [íƒœê·¸ ë¶„ì„ - í™•ì¥ ë° ì¤‘ë³µ ë°°ì œ ë¡œì§ ê°•í™”]
        tag_list = []
        for tags in self.df['ê²€ìƒ‰ì¸ì‹íƒœê·¸'].dropna():
            if tags != '-':
                parts = [t.strip() for t in str(tags).split(',')]
                tag_list.extend([t for t in parts if not any(b in t for b in self.exclude_brands)])
        
        tag_freq = Counter(tag_list).most_common(60)
        final_tags_with_count = []
        
        for t, c in tag_freq:
            if len(final_tags_with_count) >= 10: break
            
            # 1. ìƒí’ˆëª… í‚¤ì›Œë“œì™€ ì¤‘ë³µë˜ëŠ”ì§€ ì²´í¬
            if any(word in t for word in top_12_names):
                continue
            
            # 2. ì´ë¯¸ ì„ íƒëœ íƒœê·¸ë“¤ê³¼ ì¤‘ë³µ/í¬í•¨ ê´€ê³„ì¸ì§€ ì²´í¬ (í™•ì¥ì„± ê³ ë ¤)
            is_redundant = False
            for existing_t, _ in final_tags_with_count:
                # ì‹ ê·œ íƒœê·¸ê°€ ê¸°ì¡´ íƒœê·¸ë¥¼ í¬í•¨í•˜ê±°ë‚˜, ê¸°ì¡´ íƒœê·¸ê°€ ì‹ ê·œ íƒœê·¸ë¥¼ í¬í•¨í•˜ëŠ”ì§€ (ì˜ˆ: ì œê³¼ì œë¹µ vs ì œê³¼ì œë¹µì¬ë£Œ)
                if t in existing_t or existing_t in t:
                    is_redundant = True
                    break
            
            if not is_redundant:
                final_tags_with_count.append((t, c))
        
        return name_counts[:12], spec_counts[:8], final_tags_with_count

# 3. ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë° ê²°ê³¼ ì¶œë ¥
uploaded_file = st.file_uploader("ë„¤ì´ë²„ ì‡¼í•‘ ë¶„ì„ ê²°ê³¼ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"])

if uploaded_file:
    df = None
    try:
        df = pd.read_csv(uploaded_file, encoding='cp949')
    except:
        uploaded_file.seek(0)
        try:
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    if df is not None:
        manager = SEOManager(df)
        names, specs, tags = manager.run_analysis()

        st.success("âœ¨ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¨ì–´ ê°„ ì¤‘ë³µì„ ì œê±°í•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ê·¹ëŒ€í™”í–ˆìŠµë‹ˆë‹¤.")

        # --- ì„¹ì…˜ 1: ìƒí’ˆëª… ---
        st.header("ğŸ·ï¸ 1. ìƒí’ˆëª… í‚¤ì›Œë“œ (NLU ìµœì í™”)")
        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader("âœ… ì¶”ì²œ ìƒí’ˆëª… ì¡°í•©")
            recommended_title = " ".join([n[0] for n in names])
            st.code(recommended_title, language=None)
            st.info(f"**NLU ë¶„ì„ ê²°ê³¼:** ì´ {len(names)}ê°œì˜ í•µì‹¬ ìœ ì… ë‹¨ì–´ê°€ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        with col2:
            st.subheader("ğŸ“Š ë‹¨ì–´ë³„ ì‚¬ìš© ë¹ˆë„")
            name_df = pd.DataFrame(names, columns=['ë‹¨ì–´', 'ë¹ˆë„(íšŒ)'])
            st.table(name_df)
        
        with st.expander("ğŸ’¡ ìƒí’ˆëª… ì „ëµ ìƒì„¸ ì„¤ëª…"):
            st.write(f"""
            - **ì‚¬ìš© ë‹¨ì–´ ìˆ˜:** {len(names)}ë‹¨ì–´ (ë„¤ì´ë²„ nluterms ê¶Œì¥ ê¸°ì¤€ 10~12ë‹¨ì–´ ì¤€ìˆ˜)
            - **ë¶„ì„ ë‚´ìš©:** ìˆ˜ì§‘ëœ {len(df)}ê°œ ìƒí’ˆëª… ë°ì´í„°ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ë‹¨ì–´ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.
            - **ì ìš© ë¡œì§:** ë„ì–´ì“°ê¸°ë¥¼ í†µí•´ ê° ë‹¨ì–´ê°€ ë…ë¦½ì ì¸ 'í…€(Term)'ìœ¼ë¡œ ì¸ì‹ë˜ê²Œ í•˜ì—¬, ê²€ìƒ‰ ì¡°í•©(ì˜ˆ: '{names[0][0]} + {names[1][0]}') ë…¸ì¶œì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
            """)

        st.markdown("---")

        # --- ì„¹ì…˜ 2: ì†ì„± í‚¤ì›Œë“œ ---
        st.header("âš™ï¸ 2. ê¶Œì¥ ì†ì„± í‚¤ì›Œë“œ (í•„í„° ìµœì í™”)")
        col3, col4 = st.columns([2, 1])
        with col3:
            st.subheader("âœ… í•„í„° ë…¸ì¶œìš© ì†ì„±ê°’")
            for s, c in specs:
                st.button(f"{s}", key=s, use_container_width=True)
            st.caption("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë“±ë¡ í˜ì´ì§€ì˜ 'ì†ì„±'ë€ì—ì„œ ìœ„ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ ì„ íƒí•˜ì„¸ìš”.")
        with col4:
            st.subheader("ğŸ“Š ì†ì„± ì¸ì‹ ë¹ˆë„")
            spec_df = pd.DataFrame(specs, columns=['ì†ì„±ëª…', 'ì¸ì‹ íšŸìˆ˜'])
            st.table(spec_df)

        with st.expander("ğŸ’¡ ì†ì„± ì „ëµ ìƒì„¸ ì„¤ëª…"):
            st.write(f"""
            - **ë¶„ì„ ë‚´ìš©:** ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ ìƒí’ˆë“¤ì´ ê³µí†µì ìœ¼ë¡œ ë„¤ì´ë²„ ì‡¼í•‘ 'ìŠ¤í™'ë€ì— ë“±ë¡í•œ ë°ì´í„°ì…ë‹ˆë‹¤.
            - **ì ìš© ë¡œì§:** ì†Œë¹„ìê°€ 'ë©¸ê· ', 'ì‹¤ì˜¨ë³´ê´€' ë“±ì˜ ì¡°ê±´ì„ ì„ íƒí•´ ê²€ìƒ‰í•  ë•Œ(í•„í„° ì‡¼í•‘), ìƒí’ˆëª…ì— í•´ë‹¹ ë‹¨ì–´ê°€ ì—†ì–´ë„ ì†ì„±ê°’ë§Œìœ¼ë¡œ ë…¸ì¶œ ì ìˆ˜ë¥¼ ì–»ìŠµë‹ˆë‹¤.
            - **í´ë ˆì„ ë°©ì§€:** ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ìƒìœ„ ì†ì„±ê°’ ìœ„ì£¼ë¡œ ì„ ë³„í•˜ì—¬ í‘œì¤€ì ì¸ ì •ë³´ ë“±ë¡ì„ ìœ ë„í•©ë‹ˆë‹¤.
            """)

        st.markdown("---")

        # --- ì„¹ì…˜ 3: ê²€ìƒ‰ íƒœê·¸ ---
        st.header("ğŸ” 3. í™•ì¥ ê²€ìƒ‰ íƒœê·¸ (ì¤‘ë³µ ë°°ì œ ë° ì¡°í•© í™•ì¥)")
        col5, col6 = st.columns([2, 1])
        with col5:
            st.subheader("âœ… ìµœì í™” íƒœê·¸ 10ì„ ")
            tag_display = ", ".join([f"#{t[0]}" for t in tags])
            st.warning(tag_display)
            st.info(f"**ì•Œê³ ë¦¬ì¦˜ ì ìš©:** ìœ ì‚¬ ë‹¨ì–´(ì˜ˆ: {tags[0][0] if tags else ''} ê³„ì—´) ì¤‘ë³µì„ ì°¨ë‹¨í•˜ì—¬ ìœ ì… ê²½ë¡œë¥¼ ë‹¤ê°í™”í–ˆìŠµë‹ˆë‹¤.")
        with col6:
            st.subheader("ğŸ“Š íƒœê·¸ ê²€ìƒ‰ ì¸ì‹ ë¹ˆë„")
            tag_df = pd.DataFrame(tags, columns=['íƒœê·¸ëª…', 'ì¸ì‹ íšŸìˆ˜'])
            st.table(tag_df)

        with st.expander("ğŸ’¡ íƒœê·¸ í™•ì¥ ì „ëµ ìƒì„¸ ì„¤ëª…"):
            st.write("""
            - **ì¤‘ë³µ ë°°ì œ ë¡œì§:** `#ì œê³¼ì œë¹µ`ê³¼ `#ì œê³¼ì œë¹µì¬ë£Œ`ì²˜ëŸ¼ ì˜ë¯¸ê°€ ê²¹ì¹˜ëŠ” ê²½ìš°, í•˜ë‚˜ë§Œ ì„ íƒí•˜ê³  ë‚¨ì€ ìë¦¬ì— ë‹¤ë¥¸ ìœ ì˜ë¯¸í•œ í‚¤ì›Œë“œ(ì˜ˆ: #ì‹ìì¬)ë¥¼ ë°°ì¹˜í–ˆìŠµë‹ˆë‹¤.
            - **ì¡°í•© í™•ì¥:** ìƒí’ˆëª…(Title)ì—ì„œ ì¡ì§€ ëª»í•œ ì ì¬ì  ê²€ìƒ‰ì–´(ìš©ë„, íƒ€ê²Ÿ, ìƒí™©)ë¥¼ íƒœê·¸ë¡œ ë³´ì™„í•©ë‹ˆë‹¤.
            - **ë…¸ì¶œ íš¨ê³¼:** ê²€ìƒ‰ ì—”ì§„ì´ ìƒí’ˆì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ë” ë„“ê²Œ ì¸ì‹í•˜ë„ë¡ ìœ ë„í•˜ì—¬, ë¹„ì¸ê¸° ê²€ìƒ‰ì–´(Long-tail keyword) ìœ ì…ì„ ì°½ì¶œí•©ë‹ˆë‹¤.
            """)

else:
    st.info("ì‚¬ì´ë“œë°” ë˜ëŠ” ì¤‘ì•™ì˜ ì—…ë¡œë”ë¥¼ í†µí•´ ë¶„ì„ìš© CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
