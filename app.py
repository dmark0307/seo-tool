import streamlit as st
import pandas as pd
import re
from collections import Counter

# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸
st.set_page_config(page_title="ë„¤ì´ë²„ SEO NLU ë§ˆìŠ¤í„°", layout="wide")
st.title("ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ SEO í†µí•© ìµœì í™” ë§¤ë‹ˆì €")
st.markdown("---")

class SEOManager:
    def __init__(self, df, user_exclude_list):
        self.df = df
        self.exclude_brands = [
            'ë§¤ì¼', 'ì„œìš¸ìš°ìœ ', 'ì„œìš¸', 'ì—°ì„¸', 'ë‚¨ì–‘', 'ê±´êµ­', 'íŒŒìŠ¤í‡´ë¥´', 'ì¼ë™', 'í›„ë””ìŠ¤', 
            'ì†Œì™€ë‚˜ë¬´', 'ë¹™ê·¸ë ˆ', 'ì…€ë¡œëª¬', 'ë¹…ì›ë”', 'ë¯¸ê´‘ìŠ¤í† ì–´', 'ë°ì–´ë¦¬ë§ˆì¼“', 'ë„ë‚¨ìƒíšŒ', 
            'í¬ì°½ìœ ì—…', 'ë‹´í„°', 'ì—°ì„¸ìœ ì—…', 'ë§¤ì¼ìœ ì—…'
        ] + user_exclude_list
        self.sub_splits = sorted(['ìíŒê¸°', 'ìš°ìœ ', 'ë¶„ìœ ', 'ê°€ë£¨', 'ë¶„ë§', 'ì „ì§€', 'íƒˆì§€', 'ìŠ¤í‹±', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰', 'ë©¸ê· ', 'íŒŒìš°ì¹˜', 'ì¶”ì–µ', 'ê°„ì‹', 'ì¬ë£Œ'], key=len, reverse=True)

    def split_base_terms(self, text):
        if pd.isna(text) or text == '-': return []
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', str(text))
        pattern = f"({'|'.join(self.sub_splits)})"
        raw_parts = re.split(pattern, text)
        terms = []
        for part in raw_parts:
            p = part.strip()
            if not p or p in self.exclude_brands or any(c.isdigit() for c in p): continue
            if len(p) > 1 or p in self.sub_splits: terms.append(p)
        return terms

    def process_naver_stats(self, stats_file):
        """ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ í†µê³„ ì—‘ì…€ì—ì„œ ì‹¤ì œ êµ¬ë§¤ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            # ë„¤ì´ë²„ í†µê³„ íŒŒì¼ì€ ë³´í†µ cp949 ì¸ì½”ë”©ì…ë‹ˆë‹¤.
            sdf = pd.read_csv(stats_file, encoding='cp949')
        except:
            stats_file.seek(0)
            sdf = pd.read_csv(stats_file, encoding='utf-8-sig')
        
        # 'ê²€ìƒ‰í‚¤ì›Œë“œ' ì—´ê³¼ 'ê²°ì œìˆ˜' í˜¹ì€ 'ê²°ì œê¸ˆì•¡' ê¸°ì¤€ ì •ë ¬ (ì´ë¯¸ì§€ ê¸°ë°˜ ì»¬ëŸ¼ëª… ì¶”ì •)
        target_col = 'ê²€ìƒ‰í‚¤ì›Œë“œ'
        if target_col in sdf.columns:
            # ê²°ì œìˆ˜ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìœ íš¨ í‚¤ì›Œë“œ ì¶”ì¶œ
            valid_stats = sdf[sdf[target_col] != '-'].copy()
            return valid_stats[target_col].unique().tolist()[:20]
        return []

    def run_analysis(self, selected_keywords, manual_input, add_input, total_target_count):
        conv_keys = list(selected_keywords) + self.split_base_terms(manual_input)
        add_keys = self.split_base_terms(add_input)
        fixed_keywords = conv_keys + add_keys
        
        name_terms = []
        for name in self.df['ìƒí’ˆëª…']: name_terms.extend(self.split_base_terms(name))
        name_freq = Counter(name_terms).most_common(100)
        
        auto_candidates = [w for w, c in name_freq if w not in fixed_keywords]
        remain_count = max(0, total_target_count - len(fixed_keywords))
        selected_auto = auto_candidates[:remain_count]
        readable_auto_pairs = self.reorder_for_readability([(w, Counter(name_terms)[w]) for w in selected_auto])
        
        # 2. ì†ì„±(ê¸°ì¡´ ìœ ì§€)
        spec_list = []
        for spec in self.df['ìŠ¤í™'].dropna():
            parts = [p.strip() for p in str(spec).split('|')]
            spec_list.extend([p for p in parts if len(p) > 1 and p not in self.exclude_brands])
        spec_counts = Counter(spec_list).most_common(8)
        spec_keywords = set([s[0] for s in spec_counts])

        # 3. íƒœê·¸(ê¸°ì¡´ ìœ ì§€ - í™•ì¥ì„± ê·¹ëŒ€í™”)
        tag_raw_list = []
        for tags in self.df['ê²€ìƒ‰ì¸ì‹íƒœê·¸'].dropna():
            tag_raw_list.extend([t.strip() for t in str(tags).split(',') if t.strip()])
        tag_freq = Counter(tag_raw_list).most_common(300)
        
        title_keywords = set(fixed_keywords + [p[0] for p in readable_auto_pairs])
        final_tags, selected_subterms = [], set()
        master_pool = title_keywords.union(spec_keywords)

        for t_raw, c in tag_freq:
            if len(final_tags) >= 10: break
            if any(brand in t_raw for brand in self.exclude_brands): continue
            t_subterms = self.split_base_terms(t_raw)
            if not t_subterms: continue
            
            is_redundant = False
            for sub in t_subterms:
                if sub in master_pool or sub in selected_subterms:
                    is_redundant = True; break
            
            if not is_redundant:
                for ex_t, _ in final_tags:
                    if t_raw in ex_t or ex_t in t_raw:
                        is_redundant = True; break

            if not is_redundant:
                final_tags.append((t_raw, c))
                for sub in t_subterms: selected_subterms.add(sub)

        return fixed_keywords, readable_auto_pairs, spec_counts, sorted(final_tags, key=lambda x: x[1], reverse=True)[:10]

    def reorder_for_readability(self, pairs):
        identity, form, usage = ['ì „ì§€', 'ë¶„ìœ ', 'ìš°ìœ '], ['ê°€ë£¨', 'ë¶„ë§'], ['ìíŒê¸°', 'ì—…ì†Œìš©']
        def get_priority(pair):
            w = pair[0]
            if any(c in w for c in identity): return 1
            if any(c in w for c in form): return 2
            if any(c in w for c in usage): return 3
            return 4
        return sorted(pairs, key=lambda x: get_priority(x))

def calculate_seo_metrics(text):
    c_len = len(text)
    try: b_len = len(text.encode('euc-kr'))
    except: b_len = len(text.encode('utf-8'))
    return c_len, b_len

# 3. GUI êµ¬ì„±
st.sidebar.header("ğŸ“ Step 1. ë°ì´í„° ì—…ë¡œë“œ")
main_file = st.sidebar.file_uploader("1ï¸âƒ£ ë¶„ì„ìš© ìƒí’ˆ ë°ì´í„° (CSV)", type=["csv"])
stats_file = st.sidebar.file_uploader("2ï¸âƒ£ [ì„ íƒ] ë„¤ì´ë²„ ê²°ì œ í†µê³„ (CSV)", type=["csv"], help="ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ì„¼í„° > íŒë§¤ë¶„ì„ > ìƒí’ˆ/ê²€ìƒ‰ì±„ë„ì—ì„œ ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼")

if main_file:
    try: df = pd.read_csv(main_file, encoding='cp949')
    except: df = pd.read_csv(main_file, encoding='utf-8-sig')

    manager = SEOManager(df, [])
    
    # í†µê³„ íŒŒì¼ì´ ìˆìœ¼ë©´ êµ¬ë§¤ í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ
    stats_keywords = []
    if stats_file:
        stats_keywords = manager.process_naver_stats(stats_file)
        if stats_keywords:
            st.sidebar.success(f"âœ”ï¸ ê²°ì œ í‚¤ì›Œë“œ {len(stats_keywords)}ê°œ ë¡œë“œ ì™„ë£Œ!")

    st.sidebar.header("ğŸ¯ Step 2. í‚¤ì›Œë“œ ì„ íƒ")
    # í†µê³„ í‚¤ì›Œë“œì™€ ì¼ë°˜ ìƒìœ„ í‚¤ì›Œë“œë¥¼ í†µí•©í•˜ì—¬ í”½ì»¤ êµ¬ì„±
    all_picks = stats_keywords + [k for k in [p[0] for p in Counter(df['ìƒí’ˆëª…'].apply(manager.split_base_terms).sum()).most_common(30)] if k not in stats_keywords]
    
    selected_pick = st.sidebar.multiselect("ê²°ì œ/ì¸ê¸° í‚¤ì›Œë“œ í”½ì»¤", options=all_picks, default=stats_keywords[:5] if stats_keywords else [])
    manual_in = st.sidebar.text_input("ì§ì ‘ ì…ë ¥", placeholder="ì˜ˆ: ë§›ìˆëŠ”ìíŒê¸°ìš°ìœ ")
    add_in = st.sidebar.text_input("ì¶”ê°€ ë°°ì¹˜ í‚¤ì›Œë“œ")
    total_kw = st.sidebar.number_input("ìƒí’ˆëª… ëª©í‘œ í‚¤ì›Œë“œ ìˆ˜", value=11)

    fixed, auto, specs, tags = manager.run_analysis(selected_pick, manual_in, add_in, total_kw)

    # ì¶œë ¥ ì„¹ì…˜ (ë§¤ë‹ˆì €ë‹˜ ìš”ì²­ëŒ€ë¡œ ìœ ì§€)
    st.header("ğŸ·ï¸ 1. ì „ëµì  ìƒí’ˆëª… ì¡°í•©")
    full_title = " ".join(fixed + [p[0] for p in auto])
    st.code(full_title, language=None)
    c_l, b_l = calculate_seo_metrics(full_title)
    st.markdown(f"{'ğŸŸ¢ ì •ìƒ' if c_l <= 50 else 'ğŸ”´ ì£¼ì˜'}: **{c_l}ì / {b_l} Byte / {len(fixed)+len(auto)}ê°œ í‚¤ì›Œë“œ**")
    
    st.markdown("---")
    st.header("âš™ï¸ 2. í•„í„° ì†ì„± & ğŸ” 3. í™•ì¥ íƒœê·¸")
    l_col, r_col = st.columns(2)
    with l_col:
        for s_name, _ in specs: st.button(s_name, use_container_width=True, key=f"btn_{s_name}")
    with r_col:
        st.success(", ".join([f"#{t[0]}" for t in tags]))
else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
