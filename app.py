import streamlit as st
import pandas as pd
import re
from collections import Counter

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë„¤ì´ë²„ SEO í†µí•© ë¶„ì„ ë„êµ¬", layout="wide")
st.title("ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ SEO í†µí•© ìµœì í™” ë§¤ë‹ˆì €")
st.markdown("---")

# 2. ì „ë¬¸ SEO ë¶„ì„ ë¡œì§ í´ë˜ìŠ¤
class SEOManager:
    def __init__(self, df):
        self.df = df
        # ì§€ì¬ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•œ í•„í„°ë§ ë¦¬ìŠ¤íŠ¸
        self.exclude_brands = [
            'ë§¤ì¼', 'ì„œìš¸ìš°ìœ ', 'ì„œìš¸', 'ì—°ì„¸', 'ë‚¨ì–‘', 'ê±´êµ­', 'íŒŒìŠ¤í‡´ë¥´', 'ì¼ë™', 'í›„ë””ìŠ¤', 
            'ì†Œì™€ë‚˜ë¬´', 'ë¹™ê·¸ë ˆ', 'ì…€ë¡œëª¬', 'ë¹…ì›ë”', 'ë¯¸ê´‘ìŠ¤í† ì–´', 'ë°ì–´ë¦¬ë§ˆì¼“', 'ë„ë‚¨ìƒíšŒ', 
            'í¬ì°½ìœ ì—…', 'ë‹´í„°', 'ì—°ì„¸ìœ ì—…', 'ë§¤ì¼ìœ ì—…'
        ]

    def split_base_terms(self, text):
        """ë³µí•© ëª…ì‚¬ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê¸°ì´ˆ ë‹¨ì–´(Base Term) ì¶”ì¶œ"""
        if pd.isna(text) or text == '-': return []
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', str(text))
        raw_words = text.split()
        
        terms = []
        # NLU ë¶„ì„ ì‹œ ì£¼ìš”í•˜ê²Œ ìª¼ê°œì•¼ í•  í‚¤ì›Œë“œ
        sub_splits = ['ìíŒê¸°', 'ìš°ìœ ', 'ë¶„ìœ ', 'ê°€ë£¨', 'ë¶„ë§', 'ì „ì§€', 'íƒˆì§€', 'ìŠ¤í‹±', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰']
        
        for word in raw_words:
            if word in self.exclude_brands or word.isdigit(): continue
            found_sub = False
            for sub in sub_splits:
                if sub in word and word != sub:
                    terms.append(sub)
                    rem = word.replace(sub, '').strip()
                    if len(rem) > 1: terms.append(rem)
                    found_sub = True
                    break
            if not found_sub and len(word) > 1:
                terms.append(word)
        return terms

    def run_analysis(self):
        # [ìƒí’ˆëª… ë¶„ì„]
        name_terms = []
        for name in self.df['ìƒí’ˆëª…']:
            name_terms.extend(self.split_base_terms(name))
        name_counts = Counter(name_terms).most_common(20)
        top_12_names = [w for w, c in name_counts[:12]]

        # [ì†ì„± ë¶„ì„]
        spec_list = []
        for spec in self.df['ìŠ¤í™'].dropna():
            if spec != '-':
                parts = [p.strip() for p in str(spec).split('|')]
                spec_list.extend([p for p in parts if len(p) > 1 and p not in self.exclude_brands])
        spec_counts = Counter(spec_list).most_common(10)

        # [íƒœê·¸ ë¶„ì„]
        tag_list = []
        for tags in self.df['ê²€ìƒ‰ì¸ì‹íƒœê·¸'].dropna():
            if tags != '-':
                parts = [t.strip() for t in str(tags).split(',')]
                tag_list.extend([t for t in parts if not any(b in t for b in self.exclude_brands)])
        
        # ìƒí’ˆëª…ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” íƒœê·¸ ì„ ë³„
        tag_freq = Counter(tag_list).most_common(50)
        final_tags_with_count = []
        for t, c in tag_freq:
            if len(final_tags_with_count) >= 10: break
            if not any(word in t for word in top_12_names):
                final_tags_with_count.append((t, c))
        
        return name_counts[:12], spec_counts[:8], final_tags_with_count

# 3. ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë° ê²°ê³¼ ì¶œë ¥
uploaded_file = st.file_uploader("ë„¤ì´ë²„ ì‡¼í•‘ ë¶„ì„ ê²°ê³¼ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"])

if uploaded_file:
    df = None
    try:
        df = pd.read_csv(uploaded_file, encoding='cp949')
    except:
        uploaded_file.seek(0)
        try:
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    if df is not None:
        manager = SEOManager(df)
        names, specs, tags = manager.run_analysis()

        st.success("âœ¨ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê° í•­ëª©ë³„ ë¹ˆë„ìˆ˜ì™€ SEO ì „ëµì„ í™•ì¸í•˜ì„¸ìš”.")

        # --- ì„¹ì…˜ 1: ìƒí’ˆëª… ---
        st.header("ğŸ·ï¸ 1. ìƒí’ˆëª… í‚¤ì›Œë“œ (NLU ìµœì í™”)")
        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader("âœ… ì¶”ì²œ ìƒí’ˆëª… ì¡°í•©")
            recommended_title = " ".join([n[0] for n in names])
            st.code(recommended_title, language=None)
            st.markdown(f"**ê¸€ììˆ˜:** ì•½ {len(recommended_title)}ì (ê³µë°± í¬í•¨)")
        with col2:
            st.subheader("ğŸ“Š ë‹¨ì–´ë³„ ë…¸ì¶œ ë¹ˆë„")
            name_df = pd.DataFrame(names, columns=['ë‹¨ì–´', 'ë…¸ì¶œíšŸìˆ˜'])
            st.table(name_df)
        
        with st.expander("ğŸ’¡ ìƒí’ˆëª… í‚¤ì›Œë“œ ë°°ì¹˜ ì „ëµ ì„¤ëª…"):
            st.write("""
            - **ë¶„ì„ ì›ë¦¬:** ë‹¤ë¥¸ íŒë§¤ìë“¤ì´ ìƒí’ˆëª…ì— ê°€ì¥ ë§ì´ ì‚¬ìš©í•œ ë‹¨ì–´ë“¤ì„ 'ì˜ë¯¸ ë‹¨ìœ„(Term)'ë¡œ ìª¼ê°œì–´ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.
            - **ì „ëµ:** ë„¤ì´ë²„ NLU ì—”ì§„ì€ 'ìíŒê¸°ìš°ìœ 'ë³´ë‹¤ **'ìíŒê¸° ìš°ìœ '**ì™€ ê°™ì´ ë„ì–´ì“°ê¸°ëœ í˜•íƒœë¥¼ ë” ëª…í™•í•˜ê²Œ ì¸ì‹í•˜ë©°, ë‹¨ì–´ì˜ ì¡°í•© ê²€ìƒ‰ í™•ë¥ ì„ ë†’ì—¬ì¤ë‹ˆë‹¤.
            - **ì£¼ì˜ì‚¬í•­:** ë¹ˆë„ìˆ˜ê°€ ë†’ì€ ë‹¨ì–´ë¥¼ ì „ë©´ì— ë°°ì¹˜í• ìˆ˜ë¡ í´ë¦­ë¥ ê³¼ ê²€ìƒ‰ ì—°ê´€ì„± ì ìˆ˜ê°€ ìƒìŠ¹í•©ë‹ˆë‹¤.
            """)

        st.markdown("---")

        # --- ì„¹ì…˜ 2: ì†ì„± í‚¤ì›Œë“œ ---
        st.header("âš™ï¸ 2. ê¶Œì¥ ì†ì„± í‚¤ì›Œë“œ (í•„í„° ìµœì í™”)")
        col3, col4 = st.columns([2, 1])
        with col3:
            st.subheader("âœ… ì£¼ìš” ì†ì„±ê°’ ë¦¬ìŠ¤íŠ¸")
            st.write("ì•„ë˜ í‚¤ì›Œë“œë¥¼ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë“±ë¡ ì‹œ **'ì†ì„±'**ë€ì— ê²€ìƒ‰í•˜ì—¬ ì²´í¬í•˜ì„¸ìš”.")
            for s, c in specs:
                st.button(f"{s} (ê²€ìƒ‰ ì¸ì‹: {c}íšŒ)", key=s)
        with col4:
            st.subheader("ğŸ“Š ì†ì„±ë³„ ë¹ˆë„ ë°ì´í„°")
            spec_df = pd.DataFrame(specs, columns=['ì†ì„±ê°’', 'ë¹ˆë„'])
            st.table(spec_df)

        with st.expander("ğŸ’¡ ì†ì„± í‚¤ì›Œë“œ í™œìš© ì „ëµ ì„¤ëª…"):
            st.write("""
            - **ë¶„ì„ ì›ë¦¬:** ìƒìœ„ ë…¸ì¶œ ìƒí’ˆë“¤ì˜ 'ìŠ¤í™' í•­ëª©ì— ì‹¤ì œë¡œ ë“±ë¡ë˜ì–´ ë„¤ì´ë²„ í•„í„° ê²€ìƒ‰ì— ì¡íŒ ë°ì´í„°ì…ë‹ˆë‹¤.
            - **ì „ëµ:** ìƒí’ˆëª…ì— ë‹¨ì–´ë¥¼ ë‚­ë¹„í•˜ì§€ ë§ê³ , ì´ í‚¤ì›Œë“œë“¤ì„ **ì†ì„±ê°’**ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”. 
            - **íš¨ê³¼:** ì†Œë¹„ìê°€ ì‡¼í•‘ í™”ë©´ ì¢Œì¸¡ì—ì„œ 'ì‹¤ì˜¨ë³´ê´€', 'íŒŒìš°ì¹˜' ë“±ì˜ í•„í„°ë¥¼ í´ë¦­í–ˆì„ ë•Œ ë‚´ ìƒí’ˆì´ ë…¸ì¶œë˜ëŠ” í•µì‹¬ ê·¼ê±°ê°€ ë©ë‹ˆë‹¤.
            """)

        st.markdown("---")

        # --- ì„¹ì…˜ 3: ê²€ìƒ‰ íƒœê·¸ ---
        st.header("ğŸ” 3. í™•ì¥ ê²€ìƒ‰ íƒœê·¸ (ìœ ì… ê·¸ë¬¼ë§ í™•ì¥)")
        col5, col6 = st.columns([2, 1])
        with col5:
            st.subheader("âœ… ì¤‘ë³µ ì—†ëŠ” íƒœê·¸ 10ì„ ")
            tag_display = ", ".join([f"#{t[0]}" for t in tags])
            st.info(tag_display)
        with col6:
            st.subheader("ğŸ“Š íƒœê·¸ë³„ ë¹ˆë„ ë°ì´í„°")
            tag_df = pd.DataFrame(tags, columns=['íƒœê·¸ëª…', 'ë¹ˆë„'])
            st.table(tag_df)

        with st.expander("ğŸ’¡ íƒœê·¸ í‚¤ì›Œë“œ í™•ì¥ ì „ëµ ì„¤ëª…"):
            st.write("""
            - **ë¶„ì„ ì›ë¦¬:** ìƒí’ˆëª…ê³¼ ì†ì„±ì— ì‚¬ìš©ëœ ë‹¨ì–´ë¥¼ ì œì™¸í•˜ê³ , **íƒœê·¸ ì‚¬ì „**ì— ë“±ë¡ë˜ì–´ ì‹¤ì œ ìœ ì…ì„ ë§Œë“¤ì–´ë‚¸ ë‹¨ì–´ë“¤ì…ë‹ˆë‹¤.
            - **ì „ëµ:** ìƒí’ˆëª…ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ë‹¨ì–´ë¥¼ íƒœê·¸ì— ë„£ì–´ì•¼ ê²€ìƒ‰ ê·¸ë¬¼(Coverage)ì´ ë„“ì–´ì§‘ë‹ˆë‹¤. 
            - **íš¨ê³¼:** 'ì „ì§€ë¶„ìœ 'ë¥¼ ê²€ìƒ‰í•œ ì‚¬ëŒë¿ë§Œ ì•„ë‹ˆë¼ 'í™ˆë² ì´í‚¹ì¬ë£Œ', 'ì¶”ì–µì˜ë§›'ì„ ê²€ìƒ‰í•œ ì ì¬ ê³ ê°ê¹Œì§€ ë‚´ ìƒí’ˆìœ¼ë¡œ ëŒì–´ë“¤ì…ë‹ˆë‹¤.
            """)

else:
    st.info("ì‚¬ì´ë“œë°” ë˜ëŠ” ì¤‘ì•™ì˜ ì—…ë¡œë”ë¥¼ í†µí•´ ë‹¤ë¥¸ íŒë§¤ìì˜ ìƒí’ˆ ë¶„ì„ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
