import streamlit as st
import pandas as pd
import re
from collections import Counter

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë„¤ì´ë²„ SEO í†µí•© ë¶„ì„ ë„êµ¬", layout="wide")
st.title("ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ SEO í†µí•© ìµœì í™” ë§¤ë‹ˆì €")
st.markdown("---")

# 2. ì „ë¬¸ SEO ë¶„ì„ ë¡œì§ í´ë˜ìŠ¤
class SEOManager:
    def __init__(self, df):
        self.df = df
        self.exclude_brands = [
            'ë§¤ì¼', 'ì„œìš¸ìš°ìœ ', 'ì„œìš¸', 'ì—°ì„¸', 'ë‚¨ì–‘', 'ê±´êµ­', 'íŒŒìŠ¤í‡´ë¥´', 'ì¼ë™', 'í›„ë””ìŠ¤', 
            'ì†Œì™€ë‚˜ë¬´', 'ë¹™ê·¸ë ˆ', 'ì…€ë¡œëª¬', 'ë¹…ì›ë”', 'ë¯¸ê´‘ìŠ¤í† ì–´', 'ë°ì–´ë¦¬ë§ˆì¼“', 'ë„ë‚¨ìƒíšŒ', 
            'í¬ì°½ìœ ì—…', 'ë‹´í„°', 'ì—°ì„¸ìœ ì—…', 'ë§¤ì¼ìœ ì—…'
        ]

    def split_base_terms(self, text):
        """ë³µí•© ëª…ì‚¬ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê¸°ì´ˆ ë‹¨ì–´(Base Term) ì¶”ì¶œ ë° ìˆ˜ì¹˜ê°’/ë¸Œëœë“œ ì œê±°"""
        if pd.isna(text) or text == '-': return []
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', str(text))
        raw_words = text.split()
        
        terms = []
        sub_splits = ['ìíŒê¸°', 'ìš°ìœ ', 'ë¶„ìœ ', 'ê°€ë£¨', 'ë¶„ë§', 'ì „ì§€', 'íƒˆì§€', 'ìŠ¤í‹±', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰']
        
        for word in raw_words:
            if word in self.exclude_brands or any(char.isdigit() for char in word):
                continue
            
            found_sub = False
            for sub in sub_splits:
                if sub in word and word != sub:
                    terms.append(sub)
                    rem = word.replace(sub, '').strip()
                    if len(rem) > 1 and not any(char.isdigit() for char in rem):
                        terms.append(rem)
                    found_sub = True
                    break
            if not found_sub and len(word) > 1:
                terms.append(word)
        return terms

    def reorder_for_readability(self, words):
        """AI ë¶„ì„ ë‹¨ì–´ë¥¼ ê°€ë…ì„± ë†’ì€ ìˆœì„œë¡œ ì¬ë°°ì¹˜"""
        # ê·¸ë£¹ ì •ì˜
        identity = ['ì „ì§€', 'ë¶„ìœ ', 'ìš°ìœ ', 'íƒˆì§€', 'ì „ì§€ë°€'] # ì œí’ˆ ë³¸ì§ˆ
        form = ['ë¶„ë§', 'ê°€ë£¨', 'ìŠ¤í‹±', 'ì•¡ìƒ'] # ì œí˜•
        usage = ['ìíŒê¸°', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰', 'ì‹ìì¬', 'ì œê³¼', 'ì œë¹µ', 'ë² ì´í‚¹'] # ìš©ë„
        desc = ['ì§„í•œ', 'ê³ ì†Œí•œ', 'ë§›ìˆëŠ”', 'ì¶”ì–µ', 'ì¶”ì²œ', 'ì†í¸í•œ'] # ë§›/ì†ì„±/ê°ì„±

        def get_priority(word):
            if any(core in word for core in identity): return 1
            if any(core in word for core in form): return 2
            if any(core in word for core in usage): return 3
            if any(core in word for core in desc): return 4
            return 5

        # ìš°ì„ ìˆœìœ„ ê·¸ë£¹ë³„ë¡œ ì •ë ¬í•˜ë˜, ê·¸ë£¹ ë‚´ì—ì„œëŠ” ê¸°ì¡´ ë¹ˆë„ìˆœ ìœ ì§€
        return sorted(words, key=lambda x: get_priority(x))

    def run_analysis(self, manual_input):
        manual_keywords = [w.strip() for w in manual_input.split() if len(w.strip()) > 0]
        
        name_terms = []
        for name in self.df['ìƒí’ˆëª…']:
            name_terms.extend(self.split_base_terms(name))
        
        name_freq = Counter(name_terms).most_common(50)
        
        # ì¤‘ë³µ ì œê±° ë° í›„ë³´ ì„ ë³„
        auto_candidates = []
        for w, c in name_freq:
            if not any(manual_w in w or w in manual_w for manual_w in manual_keywords):
                auto_names_only = w # ë‹¨ì–´ë§Œ ì¶”ì¶œ
                auto_candidates.append(w)
        
        # 12ë‹¨ì–´ ì¤‘ ë‚¨ì€ ìˆ˜ëŸ‰ë§Œí¼ ì„ ë³„
        remain_count = max(0, 12 - len(manual_keywords))
        selected_auto = auto_candidates[:remain_count]
        
        # [í•µì‹¬] ê°€ë…ì„± ì¬ë°°ì¹˜ ì ìš©
        readable_auto = self.reorder_for_readability(selected_auto)
        
        # ì†ì„± ë° íƒœê·¸ ë¡œì§
        spec_list = []
        for spec in self.df['ìŠ¤í™'].dropna():
            if spec != '-':
                parts = [p.strip() for p in str(spec).split('|')]
                spec_list.extend([p for p in parts if len(p) > 1 and p not in self.exclude_brands])
        spec_counts = Counter(spec_list).most_common(8)

        tag_list = []
        for tags in self.df['ê²€ìƒ‰ì¸ì‹íƒœê·¸'].dropna():
            if tags != '-':
                parts = [t.strip() for t in str(tags).split(',')]
                tag_list.extend([t for t in parts if not any(b in t for b in self.exclude_brands)])
        
        tag_freq = Counter(tag_list).most_common(100)
        current_title_words = manual_keywords + readable_auto
        
        candidates = []
        for t, c in tag_freq:
            if not any(char.isdigit() for char in t) and not any(word in t for word in current_title_words):
                candidates.append({'tag': t, 'count': c})
        
        tags_to_skip = set()
        for i in range(len(candidates)):
            t1 = candidates[i]['tag']
            for j in range(len(candidates)):
                if i == j: continue
                t2 = candidates[j]['tag']
                if t1 in t2:
                    tags_to_skip.add(t1)
                    break
        
        final_pool = [c for c in candidates if c['tag'] not in tags_to_skip]
        final_tags = [(c['tag'], c['count']) for c in final_pool[:10]]
        
        return manual_keywords, readable_auto, spec_counts, final_tags

# 3. ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ (GUI)
st.sidebar.header("ğŸ“ Step 1. ë°ì´í„° ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("ë¶„ì„ìš© CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

st.sidebar.header("ğŸ¯ Step 2. ìˆ˜ë™ í‚¤ì›Œë“œ ì„¤ì •")
manual_input = st.sidebar.text_input(
    "ì‹¤ì œ êµ¬ë§¤ ìœ ì… í‚¤ì›Œë“œ ì…ë ¥", 
    placeholder="ì˜ˆ: ë§›ìˆëŠ” ì†í¸í•œ êµ­ë‚´ì‚°",
    help="ì´ í‚¤ì›Œë“œëŠ” ìƒí’ˆëª… ë§¨ ì•ì— ê³ ì •ë˜ë©°, ê°€ë…ì„± ì¬ë°°ì¹˜ ë¡œì§ì´ ì ìš©ë˜ì§€ ì•Šê³  ì…ë ¥í•œ ìˆœì„œëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤."
)

if uploaded_file:
    df = None
    try:
        df = pd.read_csv(uploaded_file, encoding='cp949')
    except:
        uploaded_file.seek(0)
        try:
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    if df is not None:
        manager = SEOManager(df)
        manual_keys, auto_keys, specs, tags = manager.run_analysis(manual_input)

        st.success("âœ¨ ê°€ë…ì„± ìµœì í™” ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

        # --- ì„¹ì…˜ 1: ìƒí’ˆëª… ---
        st.header("ğŸ·ï¸ 1. ì „ëµì  ìƒí’ˆëª… ì¡°í•© (ê°€ë…ì„± ì¬ë°°ì¹˜ ë°˜ì˜)")
        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader("âœ… ì™„ì„±ëœ ìƒí’ˆëª…")
            full_title = " ".join(manual_keys + auto_keys)
            st.code(full_title, language=None)
            st.info("**ê°€ë…ì„± ë¡œì§:** [ìˆ˜ë™ì…ë ¥] + [ì œí’ˆë³¸ì§ˆ] + [ì œí˜•] + [ìš©ë„] + [ì†ì„±] ìˆœìœ¼ë¡œ ë°°ì¹˜ë˜ì–´ ì†Œë¹„ìê°€ ì½ê¸° ê°€ì¥ í¸ì•ˆí•œ êµ¬ì¡°ì…ë‹ˆë‹¤.")
        
        with col2:
            st.subheader("ğŸ“Š ìë™ ì„ ë³„ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸")
            # ê°€ë…ì„± ìˆœì„œëŒ€ë¡œ í‘œê¸°
            st.table(pd.DataFrame(auto_keys, columns=['ì¬ë°°ì¹˜ëœ ë‹¨ì–´']))

        st.markdown("---")

        # --- ì„¹ì…˜ 2: ì†ì„± í‚¤ì›Œë“œ ---
        st.header("âš™ï¸ 2. í•„í„° ë…¸ì¶œìš© ì†ì„±ê°’")
        col3, col4 = st.columns([2, 1])
        with col3:
            st.subheader("âœ… ê¶Œì¥ ì†ì„± ë¦¬ìŠ¤íŠ¸")
            for s, c in specs:
                st.button(f"{s}", key=f"attr_{s}", use_container_width=True)
        with col4:
            st.subheader("ğŸ“Š ì†ì„± ì¸ì‹ ë°ì´í„°")
            spec_df = pd.DataFrame(specs, columns=['ì†ì„±ê°’', 'ë¹ˆë„'])
            st.table(spec_df)

        st.markdown("---")

        # --- ì„¹ì…˜ 3: í™•ì¥ íƒœê·¸ ---
        st.header("ğŸ” 3. í™•ì¥ ê²€ìƒ‰ íƒœê·¸")
        col5, col6 = st.columns([2, 1])
        with col5:
            st.subheader("âœ… ìµœì¢… íƒœê·¸ 10ì„ ")
            tag_display = ", ".join([f"#{t[0]}" for t in tags])
            st.warning(tag_display)
        with col6:
            st.subheader("ğŸ“Š íƒœê·¸ ì¸ì‹ ë°ì´í„°")
            tag_df = pd.DataFrame(tags, columns=['íƒœê·¸ëª…', 'ë¹ˆë„'])
            st.table(tag_df)

        with st.expander("ğŸ’¡ [ë§¤ë‹ˆì € í•„ë…] ê°€ë…ì„± ì¬ë°°ì¹˜ ì›ë¦¬"):
            st.write("""
            1. **ìˆ˜ë™ í‚¤ì›Œë“œ ì¡´ì¤‘:** ëŒ€í‘œë‹˜ì´ ì§ì ‘ ì…ë ¥í•˜ì‹  ë‹¨ì–´ëŠ” ì˜ë„ê°€ ëª…í™•í•˜ë¯€ë¡œ ìˆœì„œ ë³€ê²½ ì—†ì´ ë§¨ ì•ì— ë°°ì¹˜í•©ë‹ˆë‹¤.
            2. **AI í‚¤ì›Œë“œ ê·¸ë£¹í™”:** AIê°€ ë½‘ì€ í•µì‹¬ ë‹¨ì–´ë“¤ì„ ì•„ë˜ ìˆœì„œë¡œ ìë™ ì¬ì •ë ¬í•©ë‹ˆë‹¤.
                - **1ìˆœìœ„ (ë³¸ì§ˆ):** ì „ì§€, ë¶„ìœ , ìš°ìœ  ë“± ìƒí’ˆì˜ ì •ì²´ì„±
                - **2ìˆœìœ„ (í˜•íƒœ):** ë¶„ë§, ê°€ë£¨, ìŠ¤í‹± ë“± ì™¸í˜•ì  íŠ¹ì§•
                - **3ìˆœìœ„ (ìš©ë„):** ìíŒê¸°, ì—…ì†Œìš©, ë² ì´í‚¹ ë“± êµ¬ë§¤ ëª©ì 
                - **4ìˆœìœ„ (ì†ì„±):** ì§„í•œ, ê³ ì†Œí•œ, ì¶”ì–µ ë“± ê°ì„±/í’ë¯¸
            3. **ê²°ê³¼:** ê²€ìƒ‰ ë¡œì§(SEO)ì„ ë§Œì¡±í•˜ë©´ì„œë„ ê³ ê°ì´ ì½ì—ˆì„ ë•Œ ë¬¸ì¥ì´ ë§¤ë„ëŸ¬ì›Œ êµ¬ë§¤ ì „í™˜ìœ¨ì´ ë†’ì•„ì§‘ë‹ˆë‹¤.
            """)
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  êµ¬ë§¤ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ ë³´ì„¸ìš”.")
