import streamlit as st
import pandas as pd
import re
from collections import Counter

# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸ ê·¹í•œ ìµœì í™”
st.set_page_config(page_title="ë„¤ì´ë²„ SEO NLU ë§ˆìŠ¤í„°", layout="wide")

# ì‚¬ì´ë“œë°” ìŠ¤í¬ë¡¤ ë°©ì§€ ë° ì¸í„°í˜ì´ìŠ¤ ì••ì¶• CSS
st.markdown("""
    <style>
    [data-testid="stSidebar"] { min-width: 300px; max-width: 300px; }
    [data-testid="stSidebarContent"] { padding-top: 1rem; }
    [data-testid="stElementContainer"] { margin-bottom: -22px !important; }
    
    /* íŒŒì¼ ì—…ë¡œë“œ ë°•ìŠ¤ ë””ìì¸ ìµœì†Œí™” */
    [data-testid="stFileUploader"] section { padding: 0px 10px !important; min-height: 75px !important; }
    [data-testid="stFileUploader"] label { font-size: 0.8rem; margin-bottom: -15px; }
    [data-testid="stFileUploader"] section > div { display: none; } /* "Drag and drop" ë¬¸êµ¬ ì œê±° */
    
    .stTextInput label, .stNumberInput label { font-size: 0.8rem !important; }
    .block-container { padding-top: 1.5rem !important; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ SEO í†µí•© ìµœì í™” ë§¤ë‹ˆì €")
st.markdown("---")

class SEOManager:
    def __init__(self, df, user_exclude_list):
        self.df = df
        self.exclude_brands = ['ë§¤ì¼', 'ì„œìš¸ìš°ìœ ', 'ì„œìš¸', 'ì—°ì„¸', 'ë‚¨ì–‘', 'ê±´êµ­', 'íŒŒìŠ¤í‡´ë¥´', 'ì¼ë™', 'í›„ë””ìŠ¤', 'ì†Œì™€ë‚˜ë¬´', 'ë¹™ê·¸ë ˆ', 'ì…€ë¡œëª¬', 'ë¹…ì›ë”', 'ë¯¸ê´‘ìŠ¤í† ì–´', 'ë°ì–´ë¦¬ë§ˆì¼“', 'ë„ë‚¨ìƒíšŒ', 'í¬ì°½ìœ ì—…', 'ë‹´í„°', 'ì—°ì„¸ìœ ì—…', 'ë§¤ì¼ìœ ì—…'] + user_exclude_list
        self.sub_splits = sorted(['ìíŒê¸°', 'ìš°ìœ ', 'ë¶„ìœ ', 'ê°€ë£¨', 'ë¶„ë§', 'ì „ì§€', 'íƒˆì§€', 'ìŠ¤í‹±', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰', 'ë©¸ê· ', 'íŒŒìš°ì¹˜', 'ì¶”ì–µ', 'ê°„ì‹', 'ì¬ë£Œ'], key=len, reverse=True)

    def split_base_terms(self, text, is_manual=False):
        """NLU ê·œì¹™ ë¶„ë¦¬ (ìˆ˜ë™ ì…ë ¥ ì‹œ ë³´ì¡´ ë¡œì§ ê°•í™”)"""
        if pd.isna(text) or text == '-': return []
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', str(text))
        raw_words = text.split()
        terms = []
        pattern = f"({'|'.join(self.sub_splits)})"
        for word in raw_words:
            if word in self.exclude_brands: continue
            if not is_manual and any(char.isdigit() for char in word): continue
            parts = re.split(pattern, word)
            for p in parts:
                p = p.strip()
                if not p or p in self.exclude_brands: continue
                if is_manual or len(p) > 1 or p in self.sub_splits: terms.append(p)
        return terms

    def extract_stats_data(self, stats_df, target_product_code):
        """í†µê³„ ë°ì´í„°ì—ì„œ ë©”ì¸ í‚¤ì›Œë“œ, ê²°ì œ í‚¤ì›Œë“œ, ê¸°ì¡´ ìƒí’ˆëª… ì¶”ì¶œ"""
        try:
            code_col = [c for c in stats_df.columns if any(x in c for x in ['ë²ˆí˜¸', 'ID', 'ì½”ë“œ'])][0]
            kw_col = [c for c in stats_df.columns if 'í‚¤ì›Œë“œ' in c][0]
            name_col = [c for c in stats_df.columns if 'ìƒí’ˆëª…' in c][0]
            
            # 1. ì „ì²´ ë°ì´í„°ì—ì„œ ê²€ìƒ‰ ë¹ˆë„ê°€ ë†’ì€ 'ë©”ì¸ í‚¤ì›Œë“œ' ì¶”ì¶œ
            all_kws = stats_df[kw_col].dropna().apply(lambda x: self.split_base_terms(x, is_manual=True)).explode().dropna()
            main_keywords = [item[0] for item in Counter(all_kws).most_common(10) if item[0] not in self.exclude_brands]

            # 2. íŠ¹ì • ìƒí’ˆ ë§¤ì¹­ ë°ì´í„° ì¶”ì¶œ
            filtered_df = stats_df[stats_df[code_col].astype(str) == str(target_product_code)]
            if filtered_df.empty: return [], [], ""
            
            existing_name = str(filtered_df[name_col].iloc[0])
            raw_keywords = filtered_df[kw_col].dropna().unique().tolist()
            extracted = []
            for rk in raw_keywords:
                if rk != '-': extracted.extend(self.split_base_terms(rk, is_manual=True))
            
            return main_keywords, list(dict.fromkeys(extracted))[:5], existing_name
        except: return [], [], ""

    def reorder_for_readability(self, word_count_pairs):
        identity, form, usage, desc = ['ì „ì§€', 'ë¶„ìœ ', 'ìš°ìœ ', 'íƒˆì§€'], ['ë¶„ë§', 'ê°€ë£¨', 'ìŠ¤í‹±', 'ì•¡ìƒ'], ['ìíŒê¸°', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰', 'ì‹ìì¬'], ['ì§„í•œ', 'ê³ ì†Œí•œ', 'ë§›ìˆëŠ”', 'ì¶”ì–µ']
        def get_priority(pair):
            word = pair[0]
            if any(core in word for core in identity): return 1
            if any(core in word for core in form): return 2
            if any(core in word for core in usage): return 3
            if any(core in word for core in desc): return 4
            return 5
        return sorted(word_count_pairs, key=lambda x: get_priority(x))

    def run_analysis(self, stats_keywords, conversion_input, add_input, total_target_count):
        # ì…ë ¥ê°’ ë¶„í•´
        manual_conv = self.split_base_terms(conversion_input, is_manual=True)
        manual_add = self.split_base_terms(add_input, is_manual=True)
        
        # [ìš”ì²­ì‚¬í•­] ë°°ì¹˜ ìˆœì„œ ì ìš©: [í†µê³„] -> [ê³ ì •] -> [ì¶”ê°€ì „í™˜]
        fixed_keywords = []
        for k in (stats_keywords + manual_add + manual_conv):
            if k not in fixed_keywords: fixed_keywords.append(k)
        
        name_terms = []
        for name in self.df['ìƒí’ˆëª…']: name_terms.extend(self.split_base_terms(name))
        name_freq = Counter(name_terms).most_common(50)
        auto_candidates = [w for w, c in name_freq if w not in fixed_keywords]
        
        selected_auto = auto_candidates[:max(0, total_target_count - len(fixed_keywords))]
        readable_auto_pairs = self.reorder_for_readability([(w, Counter(name_terms)[w]) for w in selected_auto])
        
        # 2ë²ˆ ì„¹ì…˜: ì†ì„± ë¶„ì„ (ë¡œì§ ìœ ì§€)
        spec_list = []
        for spec in self.df['ìŠ¤í™'].dropna():
            parts = [p.strip() for p in str(spec).split('|')]
            spec_list.extend([p for p in parts if len(p) > 1 and p not in self.exclude_brands])
        specs = Counter(spec_list).most_common(8)
        spec_kws = set([s[0] for s in specs])

        # 3ë²ˆ ì„¹ì…˜: íƒœê·¸ ë¶„ì„ (ë¡œì§ ìœ ì§€)
        tag_raw = []
        for t in self.df['ê²€ìƒ‰ì¸ì‹íƒœê·¸'].dropna():
            tag_raw.extend([i.strip() for i in str(t).split(',') if i.strip()])
        tag_freq = Counter(tag_raw).most_common(300)
        title_set = set(fixed_keywords + [p[0] for p in readable_auto_pairs])
        final_tags, used_sub = [], set()
        for t_raw, c in tag_freq:
            if len(final_tags) >= 10: break
            if any(b in t_raw for b in self.exclude_brands) or any(d.isdigit() for d in t_raw): continue
            t_sub = self.split_base_terms(t_raw)
            if not t_sub or any(s in title_set or s in spec_kws or s in used_sub for s in t_sub): continue
            final_tags.append((t_raw, c)); used_sub.update(t_sub)

        return fixed_keywords, readable_auto_pairs, specs, sorted(final_tags, key=lambda x: x[1], reverse=True)[:10]

def calculate_seo_metrics(text):
    c_len = len(text)
    try: b_len = len(text.encode('euc-kr'))
    except: b_len = len(text.encode('utf-8'))
    return c_len, b_len

# --- ì‚¬ì´ë“œë°” UI ìµœì í™” êµ¬ì„± ---
with st.sidebar:
    st.markdown("### ğŸ› ï¸ **SEO ì—”ì§„ ì„¤ì •**")
    with st.expander("ğŸ“ ë°ì´í„° ì†ŒìŠ¤", expanded=True):
        uploaded_file = st.file_uploader("ìƒí’ˆ(CSV)", type=["csv"])
        stats_file = st.file_uploader("í†µê³„(XL/CSV)", type=["csv", "xlsx"])
        target_code = st.text_input("ğŸ¯ ìƒí’ˆì½”ë“œ", placeholder="ì½”ë“œ ì…ë ¥")

    with st.expander("ğŸ¯ ì „ëµ ì„¤ì •", expanded=True):
        add_in = st.text_input("ğŸ“Œ ê³ ì • ë°°ì¹˜", placeholder="ì˜ˆ: ë¬´ë£Œë°°ì†¡")
        conv_in = st.text_input("â• ì¶”ê°€ ì „í™˜", placeholder="ì˜ˆ: ë§›ìˆëŠ” ìš°ìœ ")
        total_kw = st.number_input("ğŸ”¢ ëª©í‘œ ìˆ˜", min_value=5, value=11)

if uploaded_file:
    try:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding='cp949')
    except:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')

    manager = SEOManager(df, [])
    main_kws, stats_kws, old_name = [], [], ""
    
    if stats_file and target_code:
        try:
            stats_file.seek(0)
            stats_df = pd.read_csv(stats_file, encoding='cp949') if stats_file.name.endswith('.csv') else pd.read_excel(stats_file, engine='openpyxl')
            main_kws, stats_kws, old_name = manager.extract_stats_data(stats_df, target_code)
            if stats_kws: st.sidebar.success("âœ”ï¸ í†µê³„ ë§¤ì¹­ ì™„ë£Œ")
        except: st.sidebar.error("í†µê³„ ë¶„ì„ ì˜¤ë¥˜")

    fixed, auto, specs, tags = manager.run_analysis(stats_kws, conv_in, add_in, total_kw)

    # 1. ì „ëµì  ìƒí’ˆëª… ì¡°í•©
    st.header("ğŸ·ï¸ 1. ì „ëµì  ìƒí’ˆëª… ì¡°í•©")
    col1, col2 = st.columns([2, 1])
    with col1:
        if old_name: st.info(f"ğŸ“ **ê¸°ì¡´ ìƒí’ˆëª…:** {old_name}")
        if main_kws: st.warning(f"ğŸ”¥ **í†µê³„ ê¸°ë°˜ ë©”ì¸ í‚¤ì›Œë“œ(ì¶”ì²œ):** {', '.join(main_kws)}")
            
        st.subheader("âœ… ì™„ì„±ëœ ìƒí’ˆëª…")
        full_title = " ".join(fixed + [p[0] for p in auto])
        st.code(full_title, language=None)
        cl, bl = calculate_seo_metrics(full_title)
        st.markdown(f"**{cl}ì / {bl} Byte / {len(fixed)+len(auto)}ê°œ í‚¤ì›Œë“œ**")
        if stats_kws: st.success(f"ğŸ“Š **ë°˜ì˜ëœ ê²°ì œ í‚¤ì›Œë“œ:** {', '.join(stats_kws)}")

    with col2:
        st.subheader("ğŸ“Š ìë™ ì¶”ì²œ ë¹ˆë„")
        st.table(pd.DataFrame(auto, columns=['ë‹¨ì–´', 'ë¹ˆë„']).assign(No=range(1, len(auto)+1)).set_index('No'))

    st.markdown("---")
    # 2 & 3ë²ˆ ì„¹ì…˜ (ë¡œì§ ë° ì¶œë ¥ ë°©ì‹ ì² ì €íˆ ìœ ì§€)
    st.header("âš™ï¸ 2. í•„í„° ì†ì„± & ğŸ” 3. í™•ì¥ íƒœê·¸")
    l_col, r_col = st.columns(2)
    with l_col:
        for s_name, _ in specs: st.button(s_name, use_container_width=True, key=f"at_{s_name}")
    with r_col:
        st.success(", ".join([f"#{t[0]}" for t in tags]))
else:
    st.info("ì¢Œì¸¡ ë©”ë‰´ì—ì„œ ìƒí’ˆ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
