import streamlit as st
import pandas as pd
import re
from collections import Counter

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë„¤ì´ë²„ SEO í†µí•© ë¶„ì„ ë„êµ¬", layout="wide")
st.title("ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ SEO í†µí•© ìµœì í™” ë§¤ë‹ˆì €")
st.markdown("---")

# 2. ì „ë¬¸ SEO ë¶„ì„ ë¡œì§ í´ë˜ìŠ¤
class SEOManager:
    def __init__(self, df):
        self.df = df
        # ì§€ì¬ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•œ í•„í„°ë§ ë¦¬ìŠ¤íŠ¸
        self.exclude_brands = [
            'ë§¤ì¼', 'ì„œìš¸ìš°ìœ ', 'ì„œìš¸', 'ì—°ì„¸', 'ë‚¨ì–‘', 'ê±´êµ­', 'íŒŒìŠ¤í‡´ë¥´', 'ì¼ë™', 'í›„ë””ìŠ¤', 
            'ì†Œì™€ë‚˜ë¬´', 'ë¹™ê·¸ë ˆ', 'ì…€ë¡œëª¬', 'ë¹…ì›ë”', 'ë¯¸ê´‘ìŠ¤í† ì–´', 'ë°ì–´ë¦¬ë§ˆì¼“', 'ë„ë‚¨ìƒíšŒ', 
            'í¬ì°½ìœ ì—…', 'ë‹´í„°', 'ì—°ì„¸ìœ ì—…', 'ë§¤ì¼ìœ ì—…'
        ]

    def split_base_terms(self, text):
        """ë³µí•© ëª…ì‚¬ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê¸°ì´ˆ ë‹¨ì–´(Base Term) ì¶”ì¶œ ë° ìˆ˜ì¹˜ê°’ ì œê±°"""
        if pd.isna(text) or text == '-': return []
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', str(text))
        raw_words = text.split()
        
        terms = []
        sub_splits = ['ìíŒê¸°', 'ìš°ìœ ', 'ë¶„ìœ ', 'ê°€ë£¨', 'ë¶„ë§', 'ì „ì§€', 'íƒˆì§€', 'ìŠ¤í‹±', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰']
        
        for word in raw_words:
            # [ìˆ˜ì •] ë¸Œëœë“œëª… ì œì™¸ + ìˆ«ìê°€ í¬í•¨ëœ ë‹¨ì–´(1kg, 20kg ë“±) ì „ì²´ ì œì™¸
            if word in self.exclude_brands or any(char.isdigit() for char in word):
                continue
            
            found_sub = False
            for sub in sub_splits:
                if sub in word and word != sub:
                    terms.append(sub)
                    rem = word.replace(sub, '').strip()
                    # ë¶„ë¦¬ëœ ë‹¨ì–´ì—ë„ ìˆ«ìê°€ ìˆìœ¼ë©´ ì œì™¸
                    if len(rem) > 1 and not any(char.isdigit() for char in rem):
                        terms.append(rem)
                    found_sub = True
                    break
            if not found_sub and len(word) > 1:
                terms.append(word)
        return terms

    def run_analysis(self):
        # [ìƒí’ˆëª… ë¶„ì„]
        name_terms = []
        for name in self.df['ìƒí’ˆëª…']:
            name_terms.extend(self.split_base_terms(name))
        name_counts = Counter(name_terms).most_common(20)
        top_12_names = [w for w, c in name_counts[:12]]

        # [ì†ì„± ë¶„ì„]
        spec_list = []
        for spec in self.df['ìŠ¤í™'].dropna():
            if spec != '-':
                parts = [p.strip() for p in str(spec).split('|')]
                spec_list.extend([p for p in parts if len(p) > 1 and p not in self.exclude_brands])
        spec_counts = Counter(spec_list).most_common(10)

        # [íƒœê·¸ ë¶„ì„ - í™•ì¥ì„± ë° ì¤‘ë³µ ì œê±°]
        tag_list = []
        for tags in self.df['ê²€ìƒ‰ì¸ì‹íƒœê·¸'].dropna():
            if tags != '-':
                parts = [t.strip() for t in str(tags).split(',')]
                tag_list.extend([t for t in parts if not any(b in t for b in self.exclude_brands)])
        
        tag_freq = Counter(tag_list).most_common(100)
        
        candidates = []
        for t, c in tag_freq:
            # íƒœê·¸ì—ì„œë„ ìˆ«ìê°€ í¬í•¨ëœ ê²½ìš° ì œì™¸ (í´ë ˆì„ ë°©ì§€)
            if not any(char.isdigit() for char in t) and not any(word in t for word in top_12_names):
                candidates.append({'tag': t, 'count': c})
        
        # í‚¤ì›Œë“œ í™•ì¥ ë¡œì§ (í¬í•¨ ê´€ê³„ ì •ë¦¬)
        tags_to_skip = set()
        for i in range(len(candidates)):
            t1 = candidates[i]['tag']
            for j in range(len(candidates)):
                if i == j: continue
                t2 = candidates[j]['tag']
                if t1 in t2:
                    tags_to_skip.add(t1)
                    break
        
        final_pool = [c for c in candidates if c['tag'] not in tags_to_skip]
        final_tags_with_count = [(c['tag'], c['count']) for c in final_pool[:10]]
        
        return name_counts[:12], spec_counts[:8], final_tags_with_count

# 3. ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë° ê²°ê³¼ ì¶œë ¥
uploaded_file = st.file_uploader("ë„¤ì´ë²„ ì‡¼í•‘ ë¶„ì„ ê²°ê³¼ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"])

if uploaded_file:
    df = None
    try:
        df = pd.read_csv(uploaded_file, encoding='cp949')
    except:
        uploaded_file.seek(0)
        try:
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    if df is not None:
        manager = SEOManager(df)
        names, specs, tags = manager.run_analysis()

        st.success("âœ¨ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì¹˜ê°’ì´ ì œê±°ëœ ì•ˆì „í•œ í‚¤ì›Œë“œë“¤ì´ ì„ ë³„ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # --- ì„¹ì…˜ 1: ìƒí’ˆëª… ---
        st.header("ğŸ·ï¸ 1. ìƒí’ˆëª… í‚¤ì›Œë“œ (í´ë ˆì„ ë°©ì§€ ìµœì í™”)")
        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader("âœ… ì¶”ì²œ ìƒí’ˆëª… ì¡°í•©")
            recommended_title = " ".join([n[0] for n in names])
            st.code(recommended_title, language=None)
            st.info("**ì—…ë°ì´íŠ¸:** '1kg', '20kg', '10T'ì™€ ê°™ì€ ìˆ˜ì¹˜ê°’ì„ ì œê±°í•˜ì—¬ ì˜¤ê¸°ì¬ë¡œ ì¸í•œ í´ë ˆì„ì„ ì›ì²œ ì°¨ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        with col2:
            st.subheader("ğŸ“Š ë‹¨ì–´ë³„ ë¹ˆë„")
            name_df = pd.DataFrame(names, columns=['ë‹¨ì–´', 'ë¹ˆë„'])
            st.table(name_df)

        st.markdown("---")

        # --- ì„¹ì…˜ 2: ì†ì„± í‚¤ì›Œë“œ ---
        st.header("âš™ï¸ 2. ê¶Œì¥ ì†ì„± í‚¤ì›Œë“œ (í•„í„° ê²€ìƒ‰ìš©)")
        col3, col4 = st.columns([2, 1])
        with col3:
            st.subheader("âœ… í•„í„° ìµœì í™” ì†ì„±")
            for s, c in specs:
                st.button(f"{s}", key=f"attr_{s}", use_container_width=True)
            st.caption("ì†ì„±ê°’ì—ëŠ” ì •í™•í•œ ìˆ˜ì¹˜ë¥¼ ì…ë ¥í•´ì•¼ í•˜ë¯€ë¡œ, ìˆ˜ë™ìœ¼ë¡œ í™•ì¸ í›„ ì²´í¬í•˜ì„¸ìš”.")
        with col4:
            st.subheader("ğŸ“Š ì†ì„± ì¸ì‹ ë°ì´í„°")
            spec_df = pd.DataFrame(specs, columns=['ì†ì„±ê°’', 'ë¹ˆë„'])
            st.table(spec_df)

        st.markdown("---")

        # --- ì„¹ì…˜ 3: ê²€ìƒ‰ íƒœê·¸ ---
        st.header("ğŸ” 3. í™•ì¥ ê²€ìƒ‰ íƒœê·¸ (ì¡°í•© í™•ì¥)")
        col5, col6 = st.columns([2, 1])
        with col5:
            st.subheader("âœ… ì¤‘ë³µ ë°°ì œ íƒœê·¸ 10ì„ ")
            tag_display = ", ".join([f"#{t[0]}" for t in tags])
            st.warning(tag_display)
        with col6:
            st.subheader("ğŸ“Š íƒœê·¸ ê²€ìƒ‰ ë°ì´í„°")
            tag_df = pd.DataFrame(tags, columns=['íƒœê·¸ëª…', 'ë¹ˆë„'])
            st.table(tag_df)

        with st.expander("ğŸ’¡ í•„í„°ë§ ë¡œì§ ì„¤ëª…"):
            st.write("""
            - **ìˆ˜ì¹˜ê°’ ìë™ ì œê±°:** ë‹¨ì–´ì— ìˆ«ìê°€ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´(ì˜ˆ: 1kg, 200ml) ìƒí’ˆëª…ê³¼ íƒœê·¸ í›„ë³´ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.
            - **ì´ìœ :** ìƒí’ˆëª…ì— í¬í•¨ëœ ì˜ëª»ëœ ìˆ˜ì¹˜ëŠ” ë°˜í’ˆ ë° í´ë ˆì„ì˜ ì§ì ‘ì ì¸ ì›ì¸ì´ ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
            - **ì†ì„± í™œìš©:** ì •í™•í•œ ìˆ˜ì¹˜ ì •ë³´ëŠ” ìƒí’ˆëª…ì´ ì•„ë‹Œ 'ì†ì„±'ë€ê³¼ 'ìƒì„¸í˜ì´ì§€'ì—ì„œ ì •í™•íˆ ê¸°ì¬í•˜ëŠ” ê²ƒì´ SEOì™€ ê³ ê° ì‘ëŒ€ ëª¨ë‘ì— ìœ ë¦¬í•©ë‹ˆë‹¤.
            """)

else:
    st.info("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìˆ˜ì¹˜ê°’ì„ ì œì™¸í•œ SEO ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
