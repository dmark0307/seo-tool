import streamlit as st
import pandas as pd
import re
from collections import Counter
import io

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë„¤ì´ë²„ SEO NLU ë§ˆìŠ¤í„°", layout="wide")
st.title("ğŸš€ ë„¤ì´ë²„ ì‡¼í•‘ SEO í†µí•© ìµœì í™” (í™•ì¥ì„± ê·¹ëŒ€í™” ë²„ì „)")
st.markdown("---")

class SEOManager:
    def __init__(self, df, user_exclude_list):
        self.df = df
        self.exclude_brands = set([
            'ë§¤ì¼', 'ì„œìš¸ìš°ìœ ', 'ì„œìš¸', 'ì—°ì„¸', 'ë‚¨ì–‘', 'ê±´êµ­', 'íŒŒìŠ¤í‡´ë¥´', 'ì¼ë™', 'í›„ë””ìŠ¤', 
            'ì†Œì™€ë‚˜ë¬´', 'ë¹™ê·¸ë ˆ', 'ì…€ë¡œëª¬', 'ë¹…ì›ë”', 'ë¯¸ê´‘ìŠ¤í† ì–´', 'ë°ì–´ë¦¬ë§ˆì¼“', 'ë„ë‚¨ìƒíšŒ', 
            'í¬ì°½ìœ ì—…', 'ë‹´í„°', 'ì—°ì„¸ìœ ì—…', 'ë§¤ì¼ìœ ì—…'
        ] + user_exclude_list)

    def split_base_terms(self, text):
        """ìƒí’ˆëª… ì •ë°€ ë¶„ë¦¬ (ìˆ˜ì¹˜ ë° ë¸Œëœë“œ ì œì™¸)"""
        if pd.isna(text) or text == '-': return []
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', ' ', str(text))
        words = [w.strip() for w in text.split() if len(w.strip()) > 1]
        return [w for w in words if w not in self.exclude_brands and not any(c.isdigit() for c in w)]

    def reorder_for_readability(self, word_count_pairs):
        """ê°€ë…ì„± ê·¸ë£¹ë³„ ì¬ë°°ì¹˜"""
        identity = ['ì „ì§€', 'ë¶„ìœ ', 'ìš°ìœ ', 'íƒˆì§€']
        form = ['ë¶„ë§', 'ê°€ë£¨', 'ìŠ¤í‹±', 'ì•¡ìƒ']
        usage = ['ìíŒê¸°', 'ì—…ì†Œìš©', 'ëŒ€ìš©ëŸ‰', 'ì‹ìì¬', 'ì œê³¼', 'ì œë¹µ', 'ë² ì´í‚¹']
        desc = ['ì§„í•œ', 'ê³ ì†Œí•œ', 'ë§›ìˆëŠ”', 'ì¶”ì–µ']

        def get_priority(pair):
            word = pair[0]
            if any(core in word for core in identity): return 1
            if any(core in word for core in form): return 2
            if any(core in word for core in usage): return 3
            if any(core in word for core in desc): return 4
            return 5
        return sorted(word_count_pairs, key=lambda x: get_priority(x))

    def run_analysis(self, conversion_input, add_input, total_target_count):
        # [1] ê³ ì • í‚¤ì›Œë“œ
        conv_keys = [w.strip() for w in conversion_input.split() if w.strip()]
        add_keys = [w.strip() for w in add_input.split() if w.strip()]
        fixed_keywords = conv_keys + add_keys
        
        # [2] ìƒí’ˆëª… ë¶„ì„
        all_name_words = []
        for name in self.df['ìƒí’ˆëª…']:
            all_name_words.extend(self.split_base_terms(name))
        
        name_counts = Counter(all_name_words)
        auto_candidates = [(w, c) for w, c in name_counts.most_common(100) if w not in fixed_keywords]
        
        remain_count = max(0, total_target_count - len(fixed_keywords))
        selected_auto_pairs = auto_candidates[:remain_count]
        readable_auto_pairs = self.reorder_for_readability(selected_auto_pairs)
        
        # [3] ì†ì„± ë¶„ì„
        spec_list = []
        for spec in self.df['ìŠ¤í™'].dropna():
            if spec != '-':
                parts = [p.strip() for p in str(spec).split('|')]
                spec_list.extend([p for p in parts if len(p) > 1 and p not in self.exclude_brands])
        spec_counts = Counter(spec_list).most_common(8)

        # [4] íƒœê·¸ ë¶„ì„ - â˜… ì¡°í•© í™•ì¥ì„± ê·¹ëŒ€í™” ë¡œì§ â˜…
        tag_raw_list = []
        for tags_row in self.df['ê²€ìƒ‰ì¸ì‹íƒœê·¸'].dropna():
            if tags_row != '-':
                raw_tags = [t.strip() for t in str(tags_row).split(',') if t.strip()]
                tag_raw_list.extend(raw_tags)
        
        # ì •ë°€ ì¹´ìš´íŒ… (í•„í„°ë§ ì „ ì›ë³¸ ë¹ˆë„)
        tag_freq_map = Counter(tag_raw_list)
        
        # ì œëª© ë‹¨ì–´ ì§‘í•© (ì™„ì „ ì¼ì¹˜ ì œì™¸ìš©)
        title_set = set(fixed_keywords + [p[0] for p in readable_auto_pairs])
        
        # 1ì°¨ í•„í„°ë§ (ë¸Œëœë“œ, ìˆ«ì, ì œëª© ì™„ì „ì¼ì¹˜ ì œê±°)
        pre_filtered = []
        for tag, count in tag_freq_map.most_common(500):
            if any(b in tag for b in self.exclude_brands) or any(c.isdigit() for c in tag): continue
            if tag in title_set: continue
            pre_filtered.append((tag, count))

        # --- ì¤‘ë³µ ë°°ì œ ë° ì¹´í…Œê³ ë¦¬ ë¶„ì‚° ì•Œê³ ë¦¬ì¦˜ ---
        final_tags = []
        
        # ì˜ë¯¸ ê·¸ë£¹ (ì´ ê·¸ë£¹ë‹¹ 1ê°œë§Œ ìš°ì„  ì„ ë³„í•˜ì—¬ í™•ì¥ì„± í™•ë³´)
        clusters = {
            'ì œê³¼ì œë¹µ': ['ì œê³¼', 'ì œë¹µ', 'ë² ì´í‚¹', 'ìš©í’ˆ'],
            'í’ë¯¸/ë§›': ['ë§›', 'ê³ ì†Œ', 'ì§„í•œ', 'ë‹¬ë‹¬'],
            'ìš©ë„': ['ìíŒê¸°', 'ì‹ìì¬', 'ìš”ë¦¬', 'ì‹ë‹¹'],
            'íƒ€ê²Ÿ/ì˜ì–‘': ['ë‹¨ë°±ì§ˆ', 'ì˜ì–‘', 'ê°„ì‹', 'ì–´ë¦°ì´', 'ì‚¬ë¬´ì‹¤'],
            'ì‹ ë¢°/íŠ¹ì§•': ['êµ­ë‚´ì‚°', 'ì²œì—°', 'ë¬´ì²¨ê°€', 'ìˆ˜ì…']
        }
        used_clusters = set()

        # Step A: ì¹´í…Œê³ ë¦¬ë³„ ìµœê³  ë¹ˆë„ íƒœê·¸ 1ê°œì”© ì„ ì 
        for tag, count in pre_filtered:
            for cluster_name, keywords in clusters.items():
                if any(k in tag for k in keywords) and cluster_name not in used_clusters:
                    final_tags.append((tag, count))
                    used_clusters.add(cluster_name)
                    break

        # Step B: ë‚¨ì€ ìë¦¬ë¥¼ ë¹ˆë„ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì±„ìš°ë˜, 'í¬í•¨ ê´€ê³„' ì¤‘ë³µ ì² ì € ë°°ì œ
        for tag, count in pre_filtered:
            if len(final_tags) >= 10: break
            if any(tag == existing[0] for existing in final_tags): continue
            
            # ìƒí˜¸ í¬í•¨ ê´€ê³„ ê²€ì‚¬ (ì˜ˆ: 'ì œê³¼ìš©'ì´ ì´ë¯¸ ë½‘íŒ 'ì œê³¼ì œë¹µì¬ë£Œ'ì— í¬í•¨ë˜ëŠ”ì§€ ë“±)
            is_redundant = False
            for ex_tag, _ in final_tags:
                if tag in ex_tag or ex_tag in tag:
                    is_redundant = True
                    break
            
            if not is_redundant:
                final_tags.append((tag, count))
        
        # ìµœì¢… ë¦¬ìŠ¤íŠ¸ë¥¼ ë¹ˆë„ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œ
        final_tags = sorted(final_tags, key=lambda x: x[1], reverse=True)[:10]
        
        # ê²°ê³¼ ë°˜í™˜
        return conv_keys, add_keys, readable_auto_pairs, spec_counts, final_tags, tag_freq_map.most_common(50)

# ë°”ì´íŠ¸ ê³„ì‚° í•¨ìˆ˜ (EUC-KR)
def calculate_bytes(text):
    return len(text.encode('euc-kr', errors='replace'))

# 3. ì‚¬ì´ë“œë°” ë° UI
st.sidebar.header("ğŸ“ Step 1. ë°ì´í„° ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("ë¶„ì„ìš© CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

st.sidebar.header("ğŸ¯ Step 2. ì „ëµ ì„¤ì •")
conversion_input = st.sidebar.text_input("êµ¬ë§¤ì „í™˜ í‚¤ì›Œë“œ", placeholder="ì˜ˆ: ë§›ìˆëŠ” ì†í¸í•œ")
add_input = st.sidebar.text_input("ì¶”ê°€í•  í‚¤ì›Œë“œ (ê³ ì • ë°°ì¹˜)", placeholder="ì˜ˆ: êµ­ë‚´ì‚° ë‹¹ì¼ë°œì†¡")
exclude_input = st.sidebar.text_input("ì œì™¸í•  í‚¤ì›Œë“œ (ë¶„ì„ ì œì™¸)", placeholder="ì˜ˆ: ë¸Œëœë“œëª…")
total_kw_count = st.sidebar.number_input("ìƒí’ˆëª… ì´ í‚¤ì›Œë“œ ìˆ˜ ì„¤ì •", min_value=5, max_value=25, value=11)

user_exclude_list = [w.strip() for w in exclude_input.split() if w.strip()]

if uploaded_file:
    try:
        df = pd.read_csv(uploaded_file, encoding='cp949')
    except:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')

    manager = SEOManager(df, user_exclude_list)
    conv, add, auto, specs, tags, raw_stats = manager.run_analysis(conversion_input, add_input, total_kw_count)

    st.success("âœ¨ ìµœì í™” ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ì„¹ì…˜ 1: ì „ëµì  ìƒí’ˆëª… ì¡°í•©
    st.header("ğŸ·ï¸ 1. ì „ëµì  ìƒí’ˆëª… ì¡°í•©")
    full_title = " ".join(conv + add + [p[0] for p in auto])
    title_len = len(full_title)
    total_kw_sum = len(conv) + len(add) + len(auto)
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.subheader("âœ… ì™„ì„±ëœ ìƒí’ˆëª…")
        st.code(full_title, language=None)
        
        st.markdown("---")
        m1, m2, m3 = st.columns(3)
        m1.metric("ì´ í‚¤ì›Œë“œ ìˆ˜", f"{total_kw_sum}ê°œ")
        
        status_text = "ğŸŸ¢ ì •ìƒ" if title_len <= 50 else "ğŸ”´ ì´ˆê³¼ (SEO ì£¼ì˜)"
        m2.metric("ì´ ê¸€ì ìˆ˜", f"{title_len}ì / 50ì", delta=status_text, delta_color="normal" if title_len <= 50 else "inverse")
        m3.metric("ì´ ë°”ì´íŠ¸(Byte)", f"{calculate_bytes(full_title)}B")

        st.info(f"**êµ¬ì„± ìš”ì•½:** êµ¬ë§¤ì „í™˜({len(conv)}) + ì¶”ê°€({len(add)}) + ìë™ì¶”ì²œ({len(auto)})")

    with col2:
        st.subheader("ğŸ“Š ìë™ í‚¤ì›Œë“œ ë¹ˆë„")
        auto_df = pd.DataFrame(auto, columns=['ë‹¨ì–´', 'ë¹ˆë„(íšŒ)'])
        auto_df.index += 1
        st.table(auto_df)

    st.markdown("---")

    # ì„¹ì…˜ 2: ì†ì„±
    st.header("âš™ï¸ 2. í•„í„° ë…¸ì¶œìš© ì†ì„±ê°’")
    col3, col4 = st.columns([2, 1])
    with col3:
        for s, _ in specs: st.button(s, key=f"btn_{s}", use_container_width=True)
    with col4:
        st.table(pd.DataFrame(specs, columns=['ì†ì„±ê°’', 'ë¹ˆë„']).set_index(pd.Index(range(1, len(specs)+1))))

    st.markdown("---")

    # ì„¹ì…˜ 3: íƒœê·¸ (í™•ì¥ì„± ê·¹ëŒ€í™”)
    st.header("ğŸ” 3. í™•ì¥ ê²€ìƒ‰ íƒœê·¸ (ì¡°í•© í™•ì¥ì„± ê·¹ëŒ€í™”)")
    col_t1, col_t2 = st.columns([2, 1])
    with col_t1:
        st.subheader("âœ… ìµœì í™” íƒœê·¸ 10ì„ ")
        tag_display = ", ".join([f"#{t[0]}" for t in tags])
        st.warning(tag_display)
        st.info("""
        **í™•ì¥ì„± ë¡œì§:**
        1. **ì¹´í…Œê³ ë¦¬ ë¶„ì‚°:** 'ë§›', 'ìš©ë„', 'ì˜ì–‘' ë“± ì„œë¡œ ë‹¤ë¥¸ ì†ì„±ì˜ íƒœê·¸ë¥¼ ìš°ì„  ë°°ì¹˜í•©ë‹ˆë‹¤.
        2. **ì¤‘ë³µ ì›ì²œ ì°¨ë‹¨:** ì˜ë¯¸ê°€ ê²¹ì¹˜ê±°ë‚˜ í¬í•¨ ê´€ê³„ì— ìˆëŠ” ë‹¨ì–´ë¥¼ ë°°ì œí•˜ì—¬ ìœ ì… ê²½ë¡œë¥¼ ìµœëŒ€í™”í–ˆìŠµë‹ˆë‹¤.
        """)
    with col_t2:
        st.subheader("ğŸ“Š íƒœê·¸ ì‚¬ìš© ë¹ˆë„ìˆ˜ (ì›ë³¸)")
        tag_df = pd.DataFrame(raw_stats[:20], columns=['íƒœê·¸ëª…', 'ì‚¬ìš© ë¹ˆë„ìˆ˜'])
        tag_df.index += 1
        st.table(tag_df)
else:
    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì •ë°€ SEO ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
